{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 13:00:28.146856: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.0.3) or chardet (None)/charset_normalizer (2.1.1) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from featureExtraction import featureExtraction\n",
    "from modelGenerator import modelGenerator\n",
    "from keras import backend as K \n",
    "\n",
    "N_splits = 5\n",
    "DataID = \"raw_data_10000_samples_fm_20000_tests_Prueba_21_Prueba_24_Prueba_27\"\n",
    "modelsID = ['linearSGD','svr','mlp']\n",
    "data = featureExtraction(DataID,statorFreqs=[37],testsID=[21,24],testRatio=0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 1.40821886852932    Test MAE: 0.9589128097372192  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 1.037024165967688    Test MAE: 0.7998933777193212  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 1.4482814627667784    Test MAE: 0.9126764678025362  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 1.4311769807627097    Test MAE: 0.9850848406038788  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 1.2581913181146822    Test MAE: 0.8762506469134168  \n",
      "Test MSE: 1.267370224331846    Test MAE: 0.6583118803337163  \n",
      "Test MSE: 0.8259209008875761    Test MAE: 0.7124217215377124  \n",
      "Test MSE: 0.8415984839119067    Test MAE: 0.7330927667795399  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "2023-09-28 13:00:42.062078: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.8582310501356859    Test MAE: 0.7361746472050273  \n",
      "Test MSE: 0.8580935315616918    Test MAE: 0.7073089513761517  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 13:00:42.323608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22309 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/379 [==============>...............] - ETA: 0s - loss: 10498.5625 - mean_squared_error: 10498.5625 - mean_absolute_error: 96.9089 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 13:00:42.976183: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 1s 1ms/step - loss: 7843.9702 - mean_squared_error: 7843.9702 - mean_absolute_error: 80.8817 - val_loss: 3401.2217 - val_mean_squared_error: 3401.2217 - val_mean_absolute_error: 51.4331\n",
      "Epoch 2/300\n",
      "379/379 [==============================] - 0s 923us/step - loss: 1951.9958 - mean_squared_error: 1951.9958 - mean_absolute_error: 36.9668 - val_loss: 1141.9115 - val_mean_squared_error: 1141.9115 - val_mean_absolute_error: 27.9902\n",
      "Epoch 3/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 584.1149 - mean_squared_error: 584.1149 - mean_absolute_error: 17.6776 - val_loss: 266.7298 - val_mean_squared_error: 266.7298 - val_mean_absolute_error: 11.4079\n",
      "Epoch 4/300\n",
      "379/379 [==============================] - 0s 913us/step - loss: 152.6463 - mean_squared_error: 152.6463 - mean_absolute_error: 8.4083 - val_loss: 76.2213 - val_mean_squared_error: 76.2213 - val_mean_absolute_error: 5.9150\n",
      "Epoch 5/300\n",
      "379/379 [==============================] - 0s 903us/step - loss: 44.8921 - mean_squared_error: 44.8921 - mean_absolute_error: 4.6587 - val_loss: 27.7717 - val_mean_squared_error: 27.7717 - val_mean_absolute_error: 3.5355\n",
      "Epoch 6/300\n",
      "379/379 [==============================] - 0s 913us/step - loss: 16.7900 - mean_squared_error: 16.7900 - mean_absolute_error: 3.0099 - val_loss: 15.1619 - val_mean_squared_error: 15.1619 - val_mean_absolute_error: 2.5630\n",
      "Epoch 7/300\n",
      "379/379 [==============================] - 0s 913us/step - loss: 8.1603 - mean_squared_error: 8.1603 - mean_absolute_error: 2.2326 - val_loss: 12.0632 - val_mean_squared_error: 12.0632 - val_mean_absolute_error: 2.1822\n",
      "Epoch 8/300\n",
      "379/379 [==============================] - 0s 910us/step - loss: 5.0956 - mean_squared_error: 5.0956 - mean_absolute_error: 1.8070 - val_loss: 8.4577 - val_mean_squared_error: 8.4577 - val_mean_absolute_error: 1.5549\n",
      "Epoch 9/300\n",
      "379/379 [==============================] - 0s 908us/step - loss: 3.6933 - mean_squared_error: 3.6933 - mean_absolute_error: 1.5308 - val_loss: 8.4330 - val_mean_squared_error: 8.4330 - val_mean_absolute_error: 1.6167\n",
      "Epoch 10/300\n",
      "379/379 [==============================] - 0s 911us/step - loss: 2.8307 - mean_squared_error: 2.8307 - mean_absolute_error: 1.3268 - val_loss: 6.5377 - val_mean_squared_error: 6.5377 - val_mean_absolute_error: 1.2370\n",
      "Epoch 11/300\n",
      "379/379 [==============================] - 0s 900us/step - loss: 2.3712 - mean_squared_error: 2.3712 - mean_absolute_error: 1.2013 - val_loss: 5.9584 - val_mean_squared_error: 5.9584 - val_mean_absolute_error: 1.1558\n",
      "Epoch 12/300\n",
      "379/379 [==============================] - 0s 908us/step - loss: 2.1864 - mean_squared_error: 2.1864 - mean_absolute_error: 1.1605 - val_loss: 6.6270 - val_mean_squared_error: 6.6270 - val_mean_absolute_error: 1.4262\n",
      "Epoch 13/300\n",
      "379/379 [==============================] - 0s 904us/step - loss: 2.1106 - mean_squared_error: 2.1106 - mean_absolute_error: 1.1288 - val_loss: 4.9574 - val_mean_squared_error: 4.9574 - val_mean_absolute_error: 1.0796\n",
      "Epoch 14/300\n",
      "379/379 [==============================] - 0s 907us/step - loss: 1.4138 - mean_squared_error: 1.4138 - mean_absolute_error: 0.9282 - val_loss: 5.0593 - val_mean_squared_error: 5.0593 - val_mean_absolute_error: 1.1935\n",
      "Epoch 15/300\n",
      "379/379 [==============================] - 0s 908us/step - loss: 1.4308 - mean_squared_error: 1.4308 - mean_absolute_error: 0.9328 - val_loss: 5.6438 - val_mean_squared_error: 5.6438 - val_mean_absolute_error: 1.4951\n",
      "Epoch 16/300\n",
      "379/379 [==============================] - 0s 911us/step - loss: 1.2569 - mean_squared_error: 1.2569 - mean_absolute_error: 0.8744 - val_loss: 3.3151 - val_mean_squared_error: 3.3151 - val_mean_absolute_error: 0.8040\n",
      "Epoch 17/300\n",
      "379/379 [==============================] - 0s 907us/step - loss: 1.1664 - mean_squared_error: 1.1664 - mean_absolute_error: 0.8427 - val_loss: 4.5110 - val_mean_squared_error: 4.5110 - val_mean_absolute_error: 1.1955\n",
      "Epoch 18/300\n",
      "379/379 [==============================] - 0s 905us/step - loss: 1.3057 - mean_squared_error: 1.3057 - mean_absolute_error: 0.8942 - val_loss: 8.6671 - val_mean_squared_error: 8.6671 - val_mean_absolute_error: 2.1132\n",
      "Epoch 19/300\n",
      "379/379 [==============================] - 0s 910us/step - loss: 1.1382 - mean_squared_error: 1.1382 - mean_absolute_error: 0.8271 - val_loss: 3.0836 - val_mean_squared_error: 3.0836 - val_mean_absolute_error: 1.0249\n",
      "Epoch 20/300\n",
      "379/379 [==============================] - 0s 915us/step - loss: 0.9573 - mean_squared_error: 0.9573 - mean_absolute_error: 0.7656 - val_loss: 4.4883 - val_mean_squared_error: 4.4883 - val_mean_absolute_error: 1.1406\n",
      "Epoch 21/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 1.0487 - mean_squared_error: 1.0487 - mean_absolute_error: 0.7805 - val_loss: 2.1498 - val_mean_squared_error: 2.1498 - val_mean_absolute_error: 0.6344\n",
      "Epoch 22/300\n",
      "379/379 [==============================] - 0s 911us/step - loss: 0.8154 - mean_squared_error: 0.8154 - mean_absolute_error: 0.6943 - val_loss: 2.3605 - val_mean_squared_error: 2.3605 - val_mean_absolute_error: 0.7728\n",
      "Epoch 23/300\n",
      "379/379 [==============================] - 0s 901us/step - loss: 0.8474 - mean_squared_error: 0.8474 - mean_absolute_error: 0.7239 - val_loss: 2.9497 - val_mean_squared_error: 2.9497 - val_mean_absolute_error: 0.9222\n",
      "Epoch 24/300\n",
      "379/379 [==============================] - 0s 906us/step - loss: 1.0169 - mean_squared_error: 1.0169 - mean_absolute_error: 0.7866 - val_loss: 1.9465 - val_mean_squared_error: 1.9465 - val_mean_absolute_error: 0.6404\n",
      "Epoch 25/300\n",
      "379/379 [==============================] - 0s 916us/step - loss: 0.8780 - mean_squared_error: 0.8780 - mean_absolute_error: 0.7345 - val_loss: 3.4554 - val_mean_squared_error: 3.4554 - val_mean_absolute_error: 1.3825\n",
      "Epoch 26/300\n",
      "379/379 [==============================] - 0s 908us/step - loss: 0.9365 - mean_squared_error: 0.9365 - mean_absolute_error: 0.7577 - val_loss: 1.9707 - val_mean_squared_error: 1.9707 - val_mean_absolute_error: 0.6681\n",
      "Epoch 27/300\n",
      "379/379 [==============================] - 0s 912us/step - loss: 0.9223 - mean_squared_error: 0.9223 - mean_absolute_error: 0.7530 - val_loss: 1.9055 - val_mean_squared_error: 1.9055 - val_mean_absolute_error: 0.6428\n",
      "Epoch 28/300\n",
      "379/379 [==============================] - 0s 908us/step - loss: 0.7901 - mean_squared_error: 0.7901 - mean_absolute_error: 0.7049 - val_loss: 2.9635 - val_mean_squared_error: 2.9635 - val_mean_absolute_error: 1.1327\n",
      "Epoch 29/300\n",
      "379/379 [==============================] - 0s 909us/step - loss: 0.8374 - mean_squared_error: 0.8374 - mean_absolute_error: 0.7067 - val_loss: 1.9865 - val_mean_squared_error: 1.9865 - val_mean_absolute_error: 0.6795\n",
      "Epoch 30/300\n",
      "379/379 [==============================] - 0s 910us/step - loss: 0.7535 - mean_squared_error: 0.7535 - mean_absolute_error: 0.6781 - val_loss: 2.5832 - val_mean_squared_error: 2.5832 - val_mean_absolute_error: 0.9803\n",
      "Epoch 31/300\n",
      "379/379 [==============================] - 0s 912us/step - loss: 0.8109 - mean_squared_error: 0.8109 - mean_absolute_error: 0.7093 - val_loss: 1.6090 - val_mean_squared_error: 1.6090 - val_mean_absolute_error: 0.5322\n",
      "Epoch 32/300\n",
      "379/379 [==============================] - 0s 912us/step - loss: 0.8490 - mean_squared_error: 0.8490 - mean_absolute_error: 0.7116 - val_loss: 1.7280 - val_mean_squared_error: 1.7280 - val_mean_absolute_error: 0.6474\n",
      "Epoch 33/300\n",
      "379/379 [==============================] - 0s 907us/step - loss: 0.9387 - mean_squared_error: 0.9387 - mean_absolute_error: 0.7517 - val_loss: 2.0928 - val_mean_squared_error: 2.0928 - val_mean_absolute_error: 0.8044\n",
      "Epoch 34/300\n",
      "379/379 [==============================] - 0s 912us/step - loss: 0.8479 - mean_squared_error: 0.8479 - mean_absolute_error: 0.7194 - val_loss: 2.0117 - val_mean_squared_error: 2.0117 - val_mean_absolute_error: 0.7390\n",
      "Epoch 35/300\n",
      "379/379 [==============================] - 0s 906us/step - loss: 0.7416 - mean_squared_error: 0.7416 - mean_absolute_error: 0.6721 - val_loss: 1.6918 - val_mean_squared_error: 1.6918 - val_mean_absolute_error: 0.6117\n",
      "Epoch 36/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 0.8427 - mean_squared_error: 0.8427 - mean_absolute_error: 0.7055 - val_loss: 1.6442 - val_mean_squared_error: 1.6442 - val_mean_absolute_error: 0.6290\n",
      "12/12 - 0s - loss: 1.6090 - mean_squared_error: 1.6090 - mean_absolute_error: 0.5322 - 16ms/epoch - 1ms/step\n",
      "Test MSE: 1.6090242862701416    Test MAE: 0.5322366952896118  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7872.6582 - mean_squared_error: 7872.6582 - mean_absolute_error: 80.9480 - val_loss: 3499.2256 - val_mean_squared_error: 3499.2256 - val_mean_absolute_error: 52.2311\n",
      "Epoch 2/300\n",
      "379/379 [==============================] - 0s 898us/step - loss: 1967.8929 - mean_squared_error: 1967.8929 - mean_absolute_error: 37.1972 - val_loss: 1204.5050 - val_mean_squared_error: 1204.5050 - val_mean_absolute_error: 29.0419\n",
      "Epoch 3/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 581.7985 - mean_squared_error: 581.7985 - mean_absolute_error: 17.4478 - val_loss: 275.1188 - val_mean_squared_error: 275.1188 - val_mean_absolute_error: 11.8214\n",
      "Epoch 4/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 154.1661 - mean_squared_error: 154.1661 - mean_absolute_error: 8.4796 - val_loss: 74.7373 - val_mean_squared_error: 74.7373 - val_mean_absolute_error: 5.9578\n",
      "Epoch 5/300\n",
      "379/379 [==============================] - 0s 921us/step - loss: 46.3050 - mean_squared_error: 46.3050 - mean_absolute_error: 4.6631 - val_loss: 27.2211 - val_mean_squared_error: 27.2211 - val_mean_absolute_error: 4.0491\n",
      "Epoch 6/300\n",
      "379/379 [==============================] - 0s 909us/step - loss: 17.7283 - mean_squared_error: 17.7283 - mean_absolute_error: 2.9948 - val_loss: 10.7285 - val_mean_squared_error: 10.7285 - val_mean_absolute_error: 2.4628\n",
      "Epoch 7/300\n",
      "379/379 [==============================] - 0s 903us/step - loss: 9.3453 - mean_squared_error: 9.3453 - mean_absolute_error: 2.2138 - val_loss: 5.9038 - val_mean_squared_error: 5.9038 - val_mean_absolute_error: 1.9117\n",
      "Epoch 8/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 6.4877 - mean_squared_error: 6.4877 - mean_absolute_error: 1.8615 - val_loss: 7.1350 - val_mean_squared_error: 7.1350 - val_mean_absolute_error: 2.1373\n",
      "Epoch 9/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 5.0437 - mean_squared_error: 5.0437 - mean_absolute_error: 1.6452 - val_loss: 2.6126 - val_mean_squared_error: 2.6126 - val_mean_absolute_error: 1.2316\n",
      "Epoch 10/300\n",
      "379/379 [==============================] - 0s 907us/step - loss: 3.7938 - mean_squared_error: 3.7938 - mean_absolute_error: 1.3681 - val_loss: 2.5490 - val_mean_squared_error: 2.5490 - val_mean_absolute_error: 1.3017\n",
      "Epoch 11/300\n",
      "379/379 [==============================] - 0s 904us/step - loss: 3.0850 - mean_squared_error: 3.0850 - mean_absolute_error: 1.2154 - val_loss: 1.9526 - val_mean_squared_error: 1.9526 - val_mean_absolute_error: 1.1059\n",
      "Epoch 12/300\n",
      "379/379 [==============================] - 0s 909us/step - loss: 2.7476 - mean_squared_error: 2.7476 - mean_absolute_error: 1.1440 - val_loss: 1.4817 - val_mean_squared_error: 1.4817 - val_mean_absolute_error: 0.9727\n",
      "Epoch 13/300\n",
      "379/379 [==============================] - 0s 919us/step - loss: 2.0795 - mean_squared_error: 2.0795 - mean_absolute_error: 0.9910 - val_loss: 4.2385 - val_mean_squared_error: 4.2385 - val_mean_absolute_error: 1.7217\n",
      "Epoch 14/300\n",
      "379/379 [==============================] - 0s 920us/step - loss: 2.1694 - mean_squared_error: 2.1694 - mean_absolute_error: 0.9941 - val_loss: 1.3579 - val_mean_squared_error: 1.3579 - val_mean_absolute_error: 0.9095\n",
      "Epoch 15/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 1.6812 - mean_squared_error: 1.6812 - mean_absolute_error: 0.9110 - val_loss: 1.2077 - val_mean_squared_error: 1.2077 - val_mean_absolute_error: 0.8503\n",
      "Epoch 16/300\n",
      "379/379 [==============================] - 0s 908us/step - loss: 1.6945 - mean_squared_error: 1.6945 - mean_absolute_error: 0.9129 - val_loss: 1.7803 - val_mean_squared_error: 1.7803 - val_mean_absolute_error: 1.1394\n",
      "Epoch 17/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 1.3647 - mean_squared_error: 1.3647 - mean_absolute_error: 0.8215 - val_loss: 2.6981 - val_mean_squared_error: 2.6981 - val_mean_absolute_error: 1.4444\n",
      "Epoch 18/300\n",
      "379/379 [==============================] - 0s 915us/step - loss: 1.2436 - mean_squared_error: 1.2436 - mean_absolute_error: 0.7854 - val_loss: 0.5906 - val_mean_squared_error: 0.5906 - val_mean_absolute_error: 0.6081\n",
      "Epoch 19/300\n",
      "379/379 [==============================] - 0s 923us/step - loss: 1.1013 - mean_squared_error: 1.1013 - mean_absolute_error: 0.7517 - val_loss: 0.5757 - val_mean_squared_error: 0.5757 - val_mean_absolute_error: 0.5991\n",
      "Epoch 20/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 1.0793 - mean_squared_error: 1.0793 - mean_absolute_error: 0.7495 - val_loss: 2.1321 - val_mean_squared_error: 2.1321 - val_mean_absolute_error: 1.3216\n",
      "Epoch 21/300\n",
      "379/379 [==============================] - 0s 911us/step - loss: 1.2337 - mean_squared_error: 1.2337 - mean_absolute_error: 0.7886 - val_loss: 0.7325 - val_mean_squared_error: 0.7325 - val_mean_absolute_error: 0.6776\n",
      "Epoch 22/300\n",
      "379/379 [==============================] - 0s 911us/step - loss: 0.9687 - mean_squared_error: 0.9687 - mean_absolute_error: 0.7065 - val_loss: 0.7410 - val_mean_squared_error: 0.7410 - val_mean_absolute_error: 0.6984\n",
      "Epoch 23/300\n",
      "379/379 [==============================] - 0s 915us/step - loss: 0.9460 - mean_squared_error: 0.9460 - mean_absolute_error: 0.7033 - val_loss: 1.2774 - val_mean_squared_error: 1.2774 - val_mean_absolute_error: 0.9295\n",
      "Epoch 24/300\n",
      "379/379 [==============================] - 0s 912us/step - loss: 1.3328 - mean_squared_error: 1.3328 - mean_absolute_error: 0.8191 - val_loss: 0.5807 - val_mean_squared_error: 0.5807 - val_mean_absolute_error: 0.6165\n",
      "12/12 - 0s - loss: 0.5757 - mean_squared_error: 0.5757 - mean_absolute_error: 0.5991 - 16ms/epoch - 1ms/step\n",
      "Test MSE: 0.5756708383560181    Test MAE: 0.5991352796554565  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7833.6279 - mean_squared_error: 7833.6279 - mean_absolute_error: 80.8729 - val_loss: 3278.0781 - val_mean_squared_error: 3278.0781 - val_mean_absolute_error: 50.2234\n",
      "Epoch 2/300\n",
      "379/379 [==============================] - 0s 906us/step - loss: 1925.5308 - mean_squared_error: 1925.5308 - mean_absolute_error: 36.8123 - val_loss: 1047.5267 - val_mean_squared_error: 1047.5267 - val_mean_absolute_error: 26.5615\n",
      "Epoch 3/300\n",
      "379/379 [==============================] - 0s 909us/step - loss: 547.5485 - mean_squared_error: 547.5485 - mean_absolute_error: 16.8237 - val_loss: 246.5083 - val_mean_squared_error: 246.5083 - val_mean_absolute_error: 11.2377\n",
      "Epoch 4/300\n",
      "379/379 [==============================] - 0s 909us/step - loss: 146.6667 - mean_squared_error: 146.6667 - mean_absolute_error: 8.3563 - val_loss: 65.3750 - val_mean_squared_error: 65.3750 - val_mean_absolute_error: 5.5107\n",
      "Epoch 5/300\n",
      "379/379 [==============================] - 0s 919us/step - loss: 43.9288 - mean_squared_error: 43.9288 - mean_absolute_error: 4.5984 - val_loss: 21.5376 - val_mean_squared_error: 21.5376 - val_mean_absolute_error: 3.3399\n",
      "Epoch 6/300\n",
      "379/379 [==============================] - 0s 913us/step - loss: 17.1190 - mean_squared_error: 17.1190 - mean_absolute_error: 2.9800 - val_loss: 9.5734 - val_mean_squared_error: 9.5734 - val_mean_absolute_error: 2.3997\n",
      "Epoch 7/300\n",
      "379/379 [==============================] - 0s 899us/step - loss: 9.5937 - mean_squared_error: 9.5937 - mean_absolute_error: 2.3099 - val_loss: 7.7009 - val_mean_squared_error: 7.7009 - val_mean_absolute_error: 2.2981\n",
      "Epoch 8/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 6.6794 - mean_squared_error: 6.6794 - mean_absolute_error: 1.9125 - val_loss: 3.8103 - val_mean_squared_error: 3.8103 - val_mean_absolute_error: 1.5709\n",
      "Epoch 9/300\n",
      "379/379 [==============================] - 0s 913us/step - loss: 4.4743 - mean_squared_error: 4.4743 - mean_absolute_error: 1.5310 - val_loss: 29.2467 - val_mean_squared_error: 29.2467 - val_mean_absolute_error: 4.8742\n",
      "Epoch 10/300\n",
      "379/379 [==============================] - 0s 915us/step - loss: 4.5037 - mean_squared_error: 4.5037 - mean_absolute_error: 1.4534 - val_loss: 2.7512 - val_mean_squared_error: 2.7512 - val_mean_absolute_error: 1.3515\n",
      "Epoch 11/300\n",
      "379/379 [==============================] - 0s 897us/step - loss: 3.1080 - mean_squared_error: 3.1080 - mean_absolute_error: 1.2299 - val_loss: 2.2062 - val_mean_squared_error: 2.2062 - val_mean_absolute_error: 1.1541\n",
      "Epoch 12/300\n",
      "379/379 [==============================] - 0s 905us/step - loss: 2.7777 - mean_squared_error: 2.7777 - mean_absolute_error: 1.1482 - val_loss: 1.7410 - val_mean_squared_error: 1.7410 - val_mean_absolute_error: 0.9933\n",
      "Epoch 13/300\n",
      "379/379 [==============================] - 0s 915us/step - loss: 2.2853 - mean_squared_error: 2.2853 - mean_absolute_error: 1.0390 - val_loss: 1.4266 - val_mean_squared_error: 1.4266 - val_mean_absolute_error: 0.9094\n",
      "Epoch 14/300\n",
      "379/379 [==============================] - 0s 922us/step - loss: 2.2097 - mean_squared_error: 2.2097 - mean_absolute_error: 1.0103 - val_loss: 1.6658 - val_mean_squared_error: 1.6658 - val_mean_absolute_error: 1.0087\n",
      "Epoch 15/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 1.7913 - mean_squared_error: 1.7913 - mean_absolute_error: 0.9266 - val_loss: 0.9035 - val_mean_squared_error: 0.9035 - val_mean_absolute_error: 0.7244\n",
      "Epoch 16/300\n",
      "379/379 [==============================] - 0s 910us/step - loss: 1.8079 - mean_squared_error: 1.8079 - mean_absolute_error: 0.9573 - val_loss: 0.9931 - val_mean_squared_error: 0.9931 - val_mean_absolute_error: 0.7729\n",
      "Epoch 17/300\n",
      "379/379 [==============================] - 0s 915us/step - loss: 1.4416 - mean_squared_error: 1.4416 - mean_absolute_error: 0.8316 - val_loss: 0.8702 - val_mean_squared_error: 0.8702 - val_mean_absolute_error: 0.6807\n",
      "Epoch 18/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 1.3757 - mean_squared_error: 1.3757 - mean_absolute_error: 0.8305 - val_loss: 0.8556 - val_mean_squared_error: 0.8556 - val_mean_absolute_error: 0.6953\n",
      "Epoch 19/300\n",
      "379/379 [==============================] - 0s 910us/step - loss: 1.2325 - mean_squared_error: 1.2325 - mean_absolute_error: 0.7872 - val_loss: 1.4636 - val_mean_squared_error: 1.4636 - val_mean_absolute_error: 0.9541\n",
      "Epoch 20/300\n",
      "379/379 [==============================] - 0s 913us/step - loss: 1.2081 - mean_squared_error: 1.2081 - mean_absolute_error: 0.7914 - val_loss: 1.5889 - val_mean_squared_error: 1.5889 - val_mean_absolute_error: 1.0108\n",
      "Epoch 21/300\n",
      "379/379 [==============================] - 0s 916us/step - loss: 1.2139 - mean_squared_error: 1.2139 - mean_absolute_error: 0.7841 - val_loss: 0.9975 - val_mean_squared_error: 0.9975 - val_mean_absolute_error: 0.7906\n",
      "Epoch 22/300\n",
      "379/379 [==============================] - 0s 916us/step - loss: 1.2331 - mean_squared_error: 1.2331 - mean_absolute_error: 0.7917 - val_loss: 1.0451 - val_mean_squared_error: 1.0451 - val_mean_absolute_error: 0.8282\n",
      "Epoch 23/300\n",
      "379/379 [==============================] - 0s 904us/step - loss: 0.9964 - mean_squared_error: 0.9964 - mean_absolute_error: 0.7113 - val_loss: 0.8818 - val_mean_squared_error: 0.8818 - val_mean_absolute_error: 0.6714\n",
      "12/12 - 0s - loss: 0.8556 - mean_squared_error: 0.8556 - mean_absolute_error: 0.6953 - 16ms/epoch - 1ms/step\n",
      "Test MSE: 0.855567216873169    Test MAE: 0.6952756643295288  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7919.5596 - mean_squared_error: 7919.5596 - mean_absolute_error: 81.4913 - val_loss: 3555.9629 - val_mean_squared_error: 3555.9629 - val_mean_absolute_error: 52.4942\n",
      "Epoch 2/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 1976.4808 - mean_squared_error: 1976.4808 - mean_absolute_error: 37.1276 - val_loss: 1037.3184 - val_mean_squared_error: 1037.3184 - val_mean_absolute_error: 24.9685\n",
      "Epoch 3/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 540.5181 - mean_squared_error: 540.5181 - mean_absolute_error: 16.5658 - val_loss: 289.4320 - val_mean_squared_error: 289.4320 - val_mean_absolute_error: 11.9071\n",
      "Epoch 4/300\n",
      "379/379 [==============================] - 0s 922us/step - loss: 149.6726 - mean_squared_error: 149.6726 - mean_absolute_error: 8.3197 - val_loss: 85.3847 - val_mean_squared_error: 85.3847 - val_mean_absolute_error: 6.3145\n",
      "Epoch 5/300\n",
      "379/379 [==============================] - 0s 923us/step - loss: 45.7713 - mean_squared_error: 45.7713 - mean_absolute_error: 4.6491 - val_loss: 28.4787 - val_mean_squared_error: 28.4787 - val_mean_absolute_error: 3.7189\n",
      "Epoch 6/300\n",
      "379/379 [==============================] - 0s 921us/step - loss: 18.4100 - mean_squared_error: 18.4100 - mean_absolute_error: 3.0871 - val_loss: 13.7890 - val_mean_squared_error: 13.7890 - val_mean_absolute_error: 2.7216\n",
      "Epoch 7/300\n",
      "379/379 [==============================] - 0s 925us/step - loss: 9.7774 - mean_squared_error: 9.7774 - mean_absolute_error: 2.2656 - val_loss: 7.8773 - val_mean_squared_error: 7.8773 - val_mean_absolute_error: 2.2361\n",
      "Epoch 8/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 6.4809 - mean_squared_error: 6.4809 - mean_absolute_error: 1.8708 - val_loss: 3.8134 - val_mean_squared_error: 3.8134 - val_mean_absolute_error: 1.5256\n",
      "Epoch 9/300\n",
      "379/379 [==============================] - 0s 915us/step - loss: 5.0257 - mean_squared_error: 5.0257 - mean_absolute_error: 1.6149 - val_loss: 3.4620 - val_mean_squared_error: 3.4620 - val_mean_absolute_error: 1.4527\n",
      "Epoch 10/300\n",
      "379/379 [==============================] - 0s 920us/step - loss: 4.0201 - mean_squared_error: 4.0201 - mean_absolute_error: 1.3835 - val_loss: 3.8431 - val_mean_squared_error: 3.8431 - val_mean_absolute_error: 1.4144\n",
      "Epoch 11/300\n",
      "379/379 [==============================] - 0s 926us/step - loss: 3.4624 - mean_squared_error: 3.4624 - mean_absolute_error: 1.2790 - val_loss: 4.8669 - val_mean_squared_error: 4.8669 - val_mean_absolute_error: 1.8796\n",
      "Epoch 12/300\n",
      "379/379 [==============================] - 0s 929us/step - loss: 2.6472 - mean_squared_error: 2.6472 - mean_absolute_error: 1.1264 - val_loss: 1.7057 - val_mean_squared_error: 1.7057 - val_mean_absolute_error: 1.0694\n",
      "Epoch 13/300\n",
      "379/379 [==============================] - 0s 921us/step - loss: 2.2145 - mean_squared_error: 2.2145 - mean_absolute_error: 1.0151 - val_loss: 1.9574 - val_mean_squared_error: 1.9574 - val_mean_absolute_error: 1.0453\n",
      "Epoch 14/300\n",
      "379/379 [==============================] - 0s 921us/step - loss: 2.0711 - mean_squared_error: 2.0711 - mean_absolute_error: 0.9939 - val_loss: 1.4683 - val_mean_squared_error: 1.4683 - val_mean_absolute_error: 0.9190\n",
      "Epoch 15/300\n",
      "379/379 [==============================] - 0s 924us/step - loss: 1.7362 - mean_squared_error: 1.7362 - mean_absolute_error: 0.9034 - val_loss: 1.7084 - val_mean_squared_error: 1.7084 - val_mean_absolute_error: 1.0424\n",
      "Epoch 16/300\n",
      "379/379 [==============================] - 0s 916us/step - loss: 1.5759 - mean_squared_error: 1.5759 - mean_absolute_error: 0.8716 - val_loss: 0.9578 - val_mean_squared_error: 0.9578 - val_mean_absolute_error: 0.7578\n",
      "Epoch 17/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 1.5560 - mean_squared_error: 1.5560 - mean_absolute_error: 0.8569 - val_loss: 0.6352 - val_mean_squared_error: 0.6352 - val_mean_absolute_error: 0.6317\n",
      "Epoch 18/300\n",
      "379/379 [==============================] - 0s 919us/step - loss: 1.3654 - mean_squared_error: 1.3654 - mean_absolute_error: 0.8088 - val_loss: 1.3625 - val_mean_squared_error: 1.3625 - val_mean_absolute_error: 0.9895\n",
      "Epoch 19/300\n",
      "379/379 [==============================] - 0s 933us/step - loss: 1.2932 - mean_squared_error: 1.2932 - mean_absolute_error: 0.8186 - val_loss: 1.5995 - val_mean_squared_error: 1.5995 - val_mean_absolute_error: 1.0485\n",
      "Epoch 20/300\n",
      "379/379 [==============================] - 0s 915us/step - loss: 1.1322 - mean_squared_error: 1.1322 - mean_absolute_error: 0.7549 - val_loss: 0.7839 - val_mean_squared_error: 0.7839 - val_mean_absolute_error: 0.7274\n",
      "Epoch 21/300\n",
      "379/379 [==============================] - 0s 925us/step - loss: 1.1983 - mean_squared_error: 1.1983 - mean_absolute_error: 0.7848 - val_loss: 0.5614 - val_mean_squared_error: 0.5614 - val_mean_absolute_error: 0.5760\n",
      "Epoch 22/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 1.0757 - mean_squared_error: 1.0757 - mean_absolute_error: 0.7471 - val_loss: 0.7698 - val_mean_squared_error: 0.7698 - val_mean_absolute_error: 0.7171\n",
      "Epoch 23/300\n",
      "379/379 [==============================] - 0s 922us/step - loss: 1.0138 - mean_squared_error: 1.0138 - mean_absolute_error: 0.7269 - val_loss: 0.4053 - val_mean_squared_error: 0.4053 - val_mean_absolute_error: 0.5092\n",
      "Epoch 24/300\n",
      "379/379 [==============================] - 0s 926us/step - loss: 1.1294 - mean_squared_error: 1.1294 - mean_absolute_error: 0.7591 - val_loss: 1.0249 - val_mean_squared_error: 1.0249 - val_mean_absolute_error: 0.8549\n",
      "Epoch 25/300\n",
      "379/379 [==============================] - 0s 926us/step - loss: 0.9530 - mean_squared_error: 0.9530 - mean_absolute_error: 0.6986 - val_loss: 0.8183 - val_mean_squared_error: 0.8183 - val_mean_absolute_error: 0.7275\n",
      "Epoch 26/300\n",
      "379/379 [==============================] - 0s 921us/step - loss: 0.8830 - mean_squared_error: 0.8830 - mean_absolute_error: 0.6992 - val_loss: 0.8996 - val_mean_squared_error: 0.8996 - val_mean_absolute_error: 0.7713\n",
      "Epoch 27/300\n",
      "379/379 [==============================] - 0s 916us/step - loss: 1.0410 - mean_squared_error: 1.0410 - mean_absolute_error: 0.7424 - val_loss: 0.6215 - val_mean_squared_error: 0.6215 - val_mean_absolute_error: 0.6418\n",
      "Epoch 28/300\n",
      "379/379 [==============================] - 0s 926us/step - loss: 1.0202 - mean_squared_error: 1.0202 - mean_absolute_error: 0.7346 - val_loss: 0.7492 - val_mean_squared_error: 0.7492 - val_mean_absolute_error: 0.7119\n",
      "12/12 - 0s - loss: 0.4053 - mean_squared_error: 0.4053 - mean_absolute_error: 0.5092 - 16ms/epoch - 1ms/step\n",
      "Test MSE: 0.4052990674972534    Test MAE: 0.5091595649719238  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "379/379 [==============================] - 1s 1ms/step - loss: 7752.1221 - mean_squared_error: 7752.1221 - mean_absolute_error: 80.4985 - val_loss: 3292.8604 - val_mean_squared_error: 3292.8604 - val_mean_absolute_error: 50.4189\n",
      "Epoch 2/300\n",
      "379/379 [==============================] - 0s 924us/step - loss: 1921.4939 - mean_squared_error: 1921.4939 - mean_absolute_error: 36.4589 - val_loss: 921.9366 - val_mean_squared_error: 921.9366 - val_mean_absolute_error: 23.2380\n",
      "Epoch 3/300\n",
      "379/379 [==============================] - 0s 913us/step - loss: 520.0450 - mean_squared_error: 520.0450 - mean_absolute_error: 16.0996 - val_loss: 253.7282 - val_mean_squared_error: 253.7282 - val_mean_absolute_error: 12.2620\n",
      "Epoch 4/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 141.3941 - mean_squared_error: 141.3941 - mean_absolute_error: 8.0966 - val_loss: 65.7779 - val_mean_squared_error: 65.7779 - val_mean_absolute_error: 5.5033\n",
      "Epoch 5/300\n",
      "379/379 [==============================] - 0s 921us/step - loss: 42.7492 - mean_squared_error: 42.7492 - mean_absolute_error: 4.5143 - val_loss: 22.8621 - val_mean_squared_error: 22.8621 - val_mean_absolute_error: 3.5026\n",
      "Epoch 6/300\n",
      "379/379 [==============================] - 0s 919us/step - loss: 17.3817 - mean_squared_error: 17.3817 - mean_absolute_error: 3.0110 - val_loss: 9.8410 - val_mean_squared_error: 9.8410 - val_mean_absolute_error: 2.3777\n",
      "Epoch 7/300\n",
      "379/379 [==============================] - 0s 916us/step - loss: 9.2896 - mean_squared_error: 9.2896 - mean_absolute_error: 2.2495 - val_loss: 8.3498 - val_mean_squared_error: 8.3498 - val_mean_absolute_error: 2.4838\n",
      "Epoch 8/300\n",
      "379/379 [==============================] - 0s 910us/step - loss: 6.0414 - mean_squared_error: 6.0414 - mean_absolute_error: 1.7582 - val_loss: 4.2061 - val_mean_squared_error: 4.2061 - val_mean_absolute_error: 1.6611\n",
      "Epoch 9/300\n",
      "379/379 [==============================] - 0s 911us/step - loss: 4.5009 - mean_squared_error: 4.5009 - mean_absolute_error: 1.5245 - val_loss: 2.4956 - val_mean_squared_error: 2.4956 - val_mean_absolute_error: 1.2711\n",
      "Epoch 10/300\n",
      "379/379 [==============================] - 0s 922us/step - loss: 3.7091 - mean_squared_error: 3.7091 - mean_absolute_error: 1.3476 - val_loss: 2.1640 - val_mean_squared_error: 2.1640 - val_mean_absolute_error: 1.1634\n",
      "Epoch 11/300\n",
      "379/379 [==============================] - 0s 919us/step - loss: 3.0741 - mean_squared_error: 3.0741 - mean_absolute_error: 1.2210 - val_loss: 5.0078 - val_mean_squared_error: 5.0078 - val_mean_absolute_error: 1.8839\n",
      "Epoch 12/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 2.6972 - mean_squared_error: 2.6972 - mean_absolute_error: 1.1256 - val_loss: 1.8355 - val_mean_squared_error: 1.8355 - val_mean_absolute_error: 1.1360\n",
      "Epoch 13/300\n",
      "379/379 [==============================] - 0s 920us/step - loss: 2.1017 - mean_squared_error: 2.1017 - mean_absolute_error: 1.0004 - val_loss: 1.1624 - val_mean_squared_error: 1.1624 - val_mean_absolute_error: 0.8645\n",
      "Epoch 14/300\n",
      "379/379 [==============================] - 0s 917us/step - loss: 1.9150 - mean_squared_error: 1.9150 - mean_absolute_error: 0.9470 - val_loss: 1.2897 - val_mean_squared_error: 1.2897 - val_mean_absolute_error: 0.8677\n",
      "Epoch 15/300\n",
      "379/379 [==============================] - 0s 921us/step - loss: 1.6850 - mean_squared_error: 1.6850 - mean_absolute_error: 0.8911 - val_loss: 0.6992 - val_mean_squared_error: 0.6992 - val_mean_absolute_error: 0.6507\n",
      "Epoch 16/300\n",
      "379/379 [==============================] - 0s 923us/step - loss: 1.3844 - mean_squared_error: 1.3844 - mean_absolute_error: 0.8108 - val_loss: 1.1622 - val_mean_squared_error: 1.1622 - val_mean_absolute_error: 0.8567\n",
      "Epoch 17/300\n",
      "379/379 [==============================] - 0s 920us/step - loss: 1.4068 - mean_squared_error: 1.4068 - mean_absolute_error: 0.8221 - val_loss: 0.7413 - val_mean_squared_error: 0.7413 - val_mean_absolute_error: 0.6679\n",
      "Epoch 18/300\n",
      "379/379 [==============================] - 0s 920us/step - loss: 1.4395 - mean_squared_error: 1.4395 - mean_absolute_error: 0.8563 - val_loss: 0.5013 - val_mean_squared_error: 0.5013 - val_mean_absolute_error: 0.5829\n",
      "Epoch 19/300\n",
      "379/379 [==============================] - 0s 930us/step - loss: 1.0675 - mean_squared_error: 1.0675 - mean_absolute_error: 0.7220 - val_loss: 0.5160 - val_mean_squared_error: 0.5160 - val_mean_absolute_error: 0.5732\n",
      "Epoch 20/300\n",
      "379/379 [==============================] - 0s 914us/step - loss: 1.0140 - mean_squared_error: 1.0140 - mean_absolute_error: 0.7052 - val_loss: 1.4736 - val_mean_squared_error: 1.4736 - val_mean_absolute_error: 1.0081\n",
      "Epoch 21/300\n",
      "379/379 [==============================] - 0s 929us/step - loss: 1.1144 - mean_squared_error: 1.1144 - mean_absolute_error: 0.7499 - val_loss: 1.1759 - val_mean_squared_error: 1.1759 - val_mean_absolute_error: 0.8748\n",
      "Epoch 22/300\n",
      "379/379 [==============================] - 0s 913us/step - loss: 1.0695 - mean_squared_error: 1.0695 - mean_absolute_error: 0.7557 - val_loss: 0.6449 - val_mean_squared_error: 0.6449 - val_mean_absolute_error: 0.6645\n",
      "Epoch 23/300\n",
      "379/379 [==============================] - 0s 913us/step - loss: 1.1589 - mean_squared_error: 1.1589 - mean_absolute_error: 0.7766 - val_loss: 0.6430 - val_mean_squared_error: 0.6430 - val_mean_absolute_error: 0.6384\n",
      "12/12 - 0s - loss: 0.5013 - mean_squared_error: 0.5013 - mean_absolute_error: 0.5829 - 16ms/epoch - 1ms/step\n",
      "Test MSE: 0.501309335231781    Test MAE: 0.582862913608551  \n"
     ]
    }
   ],
   "source": [
    "METRICS = []\n",
    "\n",
    "MODEL_LABELS = {\"linearSGD\": \"MLR\",\n",
    "                \"svr\": \"SVR\",\n",
    "                \"mlp\": \"MLP\"}\n",
    "\n",
    "for modelID in modelsID:\n",
    "    X =copy.deepcopy(data.X_train)\n",
    "    y =copy.deepcopy(data.y_train)\n",
    "    y_label = (y>120)*1\n",
    "    skf = StratifiedKFold(n_splits=N_splits,shuffle=True)\n",
    "    for k, (train_index, test_index) in enumerate(skf.split(X, y_label)):\n",
    "            data.X_train,data.y_train = X[train_index],y[train_index]\n",
    "            data.X_test, data.y_test  = X[test_index],y[test_index]\n",
    "            model = modelGenerator(modelID=modelID, data=data,params={})\n",
    "            model.train()\n",
    "            METRICS.append([MODEL_LABELS[modelID],k,\"MAE\",model.test_MAE])\n",
    "            METRICS.append([MODEL_LABELS[modelID],k,\"MSE\",model.test_MSE])\n",
    "            del model\n",
    "            K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{MAE} & \\multicolumn{2}{l}{MSE} \\\\\n",
      "{} &  mean &   std &  mean &   std \\\\\n",
      "Model &       &       &       &       \\\\\n",
      "\\midrule\n",
      "MLR   & 0.907 & 0.073 & 1.317 & 0.174 \\\\\n",
      "SVR   & 0.709 & 0.031 & 0.930 & 0.189 \\\\\n",
      "MLP   & 0.584 & 0.072 & 0.789 & 0.488 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63801/4070562265.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(table_metrics.to_latex(float_format=\"%1.3f\"))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_metrics = pd.DataFrame(METRICS,columns = ['Model','k','METRICS','VALUES'])\n",
    "table_metrics = df_metrics.pivot_table(index='Model',columns='METRICS',values=\"VALUES\",aggfunc=[np.mean, np.std])\n",
    "table_metrics = table_metrics.swaplevel(axis=1)\n",
    "table_metrics.sort_index(axis=1,inplace=True)\n",
    "table_metrics.columns.names = (None,None)\n",
    "table_metrics = table_metrics.reindex([MODEL_LABELS[model] for model in modelsID])\n",
    "print(table_metrics.to_latex(float_format=\"%1.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiwind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
