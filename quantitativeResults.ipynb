{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 10:30:41.932252: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "from featureExtraction import featureExtraction\n",
    "from modelGenerator import modelGenerator\n",
    "from keras import backend as K \n",
    "\n",
    "N_splits = 10\n",
    "DataID = \"raw_data_10000_samples_fm_20000_tests_Prueba_21_Prueba_24_Prueba_27\"\n",
    "modelsID = ['linearSGD','svr','mlp']\n",
    "data = featureExtraction(DataID,statorFreqs=[37],testsID=[21,24,27]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 0.9585564856123828    Test MAE: 0.7835871793515622  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 0.9709748528009229    Test MAE: 0.7915878468825965  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 0.9621470379764003    Test MAE: 0.7864160915936066  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 0.9182131643580059    Test MAE: 0.7718403317066014  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 0.8008288808819909    Test MAE: 0.7097454690821922  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 0.9920540165150467    Test MAE: 0.8397398834557994  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 1.3611304016482755    Test MAE: 0.8896393558229359  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 1.015744460124418    Test MAE: 0.8191498325921844  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 0.9639539389408646    Test MAE: 0.7993370628893463  \n",
      "training <class 'models.linearSGD.linearSGD'>\n",
      "Test MSE: 1.6765282243671966    Test MAE: 0.8676511055264073  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 5.270431370609156    Test MAE: 1.9902285716975718  \n",
      "Test MSE: 4.383816296560377    Test MAE: 1.893027432383196  \n",
      "Test MSE: 2.2148595758871377    Test MAE: 1.3168609617144245  \n",
      "Test MSE: 3.060490668667916    Test MAE: 1.476434252238393  \n",
      "Test MSE: 1.696142634452597    Test MAE: 1.1254734614161712  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/diego/.conda/envs/hiwind/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=300).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 3.433538852105794    Test MAE: 1.6621132888440544  \n",
      "Test MSE: 5.001828740726791    Test MAE: 2.0256003136205707  \n",
      "Test MSE: 1.656115515214603    Test MAE: 1.0372445534685801  \n",
      "Test MSE: 5.674913050133177    Test MAE: 2.210539045569121  \n",
      "Test MSE: 14.514289688378865    Test MAE: 3.408547995905327  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 10:30:53.568980: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-08 10:30:53.831269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22309 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/677 [=======>......................] - ETA: 0s - loss: 13773.4717 - mean_squared_error: 13773.4717 - mean_absolute_error: 113.8147"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 10:30:54.473649: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677/677 [==============================] - 1s 959us/step - loss: 7121.7368 - mean_squared_error: 7121.7368 - mean_absolute_error: 75.8824 - val_loss: 1576.5862 - val_mean_squared_error: 1576.5862 - val_mean_absolute_error: 36.0425\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 855us/step - loss: 582.7851 - mean_squared_error: 582.7851 - mean_absolute_error: 19.2576 - val_loss: 98.2013 - val_mean_squared_error: 98.2013 - val_mean_absolute_error: 7.7924\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 42.9195 - mean_squared_error: 42.9195 - mean_absolute_error: 5.0168 - val_loss: 14.2464 - val_mean_squared_error: 14.2464 - val_mean_absolute_error: 3.0236\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 10.6033 - mean_squared_error: 10.6033 - mean_absolute_error: 2.5588 - val_loss: 5.1446 - val_mean_squared_error: 5.1446 - val_mean_absolute_error: 1.8341\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 5.9569 - mean_squared_error: 5.9569 - mean_absolute_error: 1.8700 - val_loss: 3.4868 - val_mean_squared_error: 3.4868 - val_mean_absolute_error: 1.4801\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 836us/step - loss: 4.5739 - mean_squared_error: 4.5739 - mean_absolute_error: 1.6217 - val_loss: 4.3997 - val_mean_squared_error: 4.3997 - val_mean_absolute_error: 1.6647\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 3.5619 - mean_squared_error: 3.5619 - mean_absolute_error: 1.4170 - val_loss: 2.5724 - val_mean_squared_error: 2.5724 - val_mean_absolute_error: 1.3027\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 2.9864 - mean_squared_error: 2.9864 - mean_absolute_error: 1.2850 - val_loss: 1.9368 - val_mean_squared_error: 1.9368 - val_mean_absolute_error: 1.1068\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 837us/step - loss: 2.5343 - mean_squared_error: 2.5343 - mean_absolute_error: 1.1816 - val_loss: 1.0791 - val_mean_squared_error: 1.0791 - val_mean_absolute_error: 0.8369\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 836us/step - loss: 2.0261 - mean_squared_error: 2.0261 - mean_absolute_error: 1.0617 - val_loss: 1.7398 - val_mean_squared_error: 1.7398 - val_mean_absolute_error: 1.1031\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 844us/step - loss: 1.6079 - mean_squared_error: 1.6079 - mean_absolute_error: 0.9471 - val_loss: 0.6738 - val_mean_squared_error: 0.6738 - val_mean_absolute_error: 0.6671\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 834us/step - loss: 1.4960 - mean_squared_error: 1.4960 - mean_absolute_error: 0.8848 - val_loss: 0.8112 - val_mean_squared_error: 0.8112 - val_mean_absolute_error: 0.7382\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 839us/step - loss: 1.1810 - mean_squared_error: 1.1810 - mean_absolute_error: 0.7995 - val_loss: 0.6327 - val_mean_squared_error: 0.6327 - val_mean_absolute_error: 0.6433\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 841us/step - loss: 1.2098 - mean_squared_error: 1.2098 - mean_absolute_error: 0.8293 - val_loss: 0.8161 - val_mean_squared_error: 0.8161 - val_mean_absolute_error: 0.7307\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 1.1734 - mean_squared_error: 1.1734 - mean_absolute_error: 0.8090 - val_loss: 1.3675 - val_mean_squared_error: 1.3675 - val_mean_absolute_error: 0.9882\n",
      "Epoch 16/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.0911 - mean_squared_error: 1.0911 - mean_absolute_error: 0.7692 - val_loss: 0.4827 - val_mean_squared_error: 0.4827 - val_mean_absolute_error: 0.5514\n",
      "Epoch 17/300\n",
      "677/677 [==============================] - 1s 837us/step - loss: 0.9353 - mean_squared_error: 0.9353 - mean_absolute_error: 0.7396 - val_loss: 0.7349 - val_mean_squared_error: 0.7349 - val_mean_absolute_error: 0.6929\n",
      "Epoch 18/300\n",
      "677/677 [==============================] - 1s 839us/step - loss: 1.1171 - mean_squared_error: 1.1171 - mean_absolute_error: 0.7929 - val_loss: 0.8165 - val_mean_squared_error: 0.8165 - val_mean_absolute_error: 0.7185\n",
      "Epoch 19/300\n",
      "677/677 [==============================] - 1s 830us/step - loss: 1.0009 - mean_squared_error: 1.0009 - mean_absolute_error: 0.7616 - val_loss: 0.5572 - val_mean_squared_error: 0.5572 - val_mean_absolute_error: 0.5891\n",
      "Epoch 20/300\n",
      "677/677 [==============================] - 1s 836us/step - loss: 1.1056 - mean_squared_error: 1.1056 - mean_absolute_error: 0.7922 - val_loss: 0.6240 - val_mean_squared_error: 0.6240 - val_mean_absolute_error: 0.6245\n",
      "Epoch 21/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 1.0138 - mean_squared_error: 1.0138 - mean_absolute_error: 0.7570 - val_loss: 2.1384 - val_mean_squared_error: 2.1384 - val_mean_absolute_error: 1.2354\n",
      "10/10 - 0s - loss: 0.4827 - mean_squared_error: 0.4827 - mean_absolute_error: 0.5514 - 15ms/epoch - 1ms/step\n",
      "Test MSE: 0.48267996311187744    Test MAE: 0.551417887210846  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "677/677 [==============================] - 1s 924us/step - loss: 7146.5771 - mean_squared_error: 7146.5771 - mean_absolute_error: 75.8986 - val_loss: 1593.6255 - val_mean_squared_error: 1593.6255 - val_mean_absolute_error: 36.0829\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 569.0093 - mean_squared_error: 569.0093 - mean_absolute_error: 18.8142 - val_loss: 107.4016 - val_mean_squared_error: 107.4016 - val_mean_absolute_error: 8.2145\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 42.0074 - mean_squared_error: 42.0074 - mean_absolute_error: 4.8881 - val_loss: 17.6012 - val_mean_squared_error: 17.6012 - val_mean_absolute_error: 3.5678\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 10.2656 - mean_squared_error: 10.2656 - mean_absolute_error: 2.5095 - val_loss: 6.6306 - val_mean_squared_error: 6.6306 - val_mean_absolute_error: 2.1184\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 5.7811 - mean_squared_error: 5.7811 - mean_absolute_error: 1.8380 - val_loss: 4.3576 - val_mean_squared_error: 4.3576 - val_mean_absolute_error: 1.6882\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 4.6534 - mean_squared_error: 4.6534 - mean_absolute_error: 1.6198 - val_loss: 3.5137 - val_mean_squared_error: 3.5137 - val_mean_absolute_error: 1.4262\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 3.7867 - mean_squared_error: 3.7867 - mean_absolute_error: 1.4646 - val_loss: 2.8783 - val_mean_squared_error: 2.8783 - val_mean_absolute_error: 1.3488\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 3.1965 - mean_squared_error: 3.1965 - mean_absolute_error: 1.3307 - val_loss: 2.6645 - val_mean_squared_error: 2.6645 - val_mean_absolute_error: 1.2883\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 841us/step - loss: 2.6666 - mean_squared_error: 2.6666 - mean_absolute_error: 1.1965 - val_loss: 2.0116 - val_mean_squared_error: 2.0116 - val_mean_absolute_error: 1.0853\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 844us/step - loss: 2.2798 - mean_squared_error: 2.2798 - mean_absolute_error: 1.1028 - val_loss: 2.8357 - val_mean_squared_error: 2.8357 - val_mean_absolute_error: 1.3448\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 1.6459 - mean_squared_error: 1.6459 - mean_absolute_error: 0.9402 - val_loss: 1.4239 - val_mean_squared_error: 1.4239 - val_mean_absolute_error: 0.8789\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 1.4828 - mean_squared_error: 1.4828 - mean_absolute_error: 0.8977 - val_loss: 1.5282 - val_mean_squared_error: 1.5282 - val_mean_absolute_error: 0.9304\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 1.4152 - mean_squared_error: 1.4152 - mean_absolute_error: 0.8724 - val_loss: 0.8735 - val_mean_squared_error: 0.8735 - val_mean_absolute_error: 0.6572\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.1382 - mean_squared_error: 1.1382 - mean_absolute_error: 0.7985 - val_loss: 1.2810 - val_mean_squared_error: 1.2810 - val_mean_absolute_error: 0.9305\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 1.1987 - mean_squared_error: 1.1987 - mean_absolute_error: 0.8062 - val_loss: 0.9947 - val_mean_squared_error: 0.9947 - val_mean_absolute_error: 0.7206\n",
      "Epoch 16/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 1.1020 - mean_squared_error: 1.1020 - mean_absolute_error: 0.8023 - val_loss: 0.9624 - val_mean_squared_error: 0.9624 - val_mean_absolute_error: 0.7814\n",
      "Epoch 17/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 1.0425 - mean_squared_error: 1.0425 - mean_absolute_error: 0.7627 - val_loss: 0.7750 - val_mean_squared_error: 0.7750 - val_mean_absolute_error: 0.6567\n",
      "Epoch 18/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 1.0073 - mean_squared_error: 1.0073 - mean_absolute_error: 0.7731 - val_loss: 0.6734 - val_mean_squared_error: 0.6734 - val_mean_absolute_error: 0.6220\n",
      "Epoch 19/300\n",
      "677/677 [==============================] - 1s 841us/step - loss: 1.1189 - mean_squared_error: 1.1189 - mean_absolute_error: 0.7910 - val_loss: 0.7089 - val_mean_squared_error: 0.7089 - val_mean_absolute_error: 0.6529\n",
      "Epoch 20/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 0.9926 - mean_squared_error: 0.9926 - mean_absolute_error: 0.7648 - val_loss: 1.7086 - val_mean_squared_error: 1.7086 - val_mean_absolute_error: 1.0936\n",
      "Epoch 21/300\n",
      "677/677 [==============================] - 1s 844us/step - loss: 1.0310 - mean_squared_error: 1.0310 - mean_absolute_error: 0.7715 - val_loss: 1.7512 - val_mean_squared_error: 1.7512 - val_mean_absolute_error: 1.0778\n",
      "Epoch 22/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 0.8765 - mean_squared_error: 0.8765 - mean_absolute_error: 0.7178 - val_loss: 0.7824 - val_mean_squared_error: 0.7824 - val_mean_absolute_error: 0.6663\n",
      "Epoch 23/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 0.9676 - mean_squared_error: 0.9676 - mean_absolute_error: 0.7556 - val_loss: 1.3400 - val_mean_squared_error: 1.3400 - val_mean_absolute_error: 0.9481\n",
      "10/10 - 0s - loss: 0.6734 - mean_squared_error: 0.6734 - mean_absolute_error: 0.6220 - 15ms/epoch - 2ms/step\n",
      "Test MSE: 0.6733507513999939    Test MAE: 0.621993362903595  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "677/677 [==============================] - 1s 933us/step - loss: 7158.7666 - mean_squared_error: 7158.7666 - mean_absolute_error: 75.8490 - val_loss: 1648.3357 - val_mean_squared_error: 1648.3357 - val_mean_absolute_error: 36.7675\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 841us/step - loss: 583.4147 - mean_squared_error: 583.4147 - mean_absolute_error: 19.2257 - val_loss: 98.6753 - val_mean_squared_error: 98.6753 - val_mean_absolute_error: 7.8749\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 42.4131 - mean_squared_error: 42.4131 - mean_absolute_error: 4.9869 - val_loss: 13.6461 - val_mean_squared_error: 13.6461 - val_mean_absolute_error: 2.8611\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 9.8761 - mean_squared_error: 9.8761 - mean_absolute_error: 2.4717 - val_loss: 5.7080 - val_mean_squared_error: 5.7080 - val_mean_absolute_error: 1.8939\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 5.7118 - mean_squared_error: 5.7118 - mean_absolute_error: 1.8161 - val_loss: 4.5973 - val_mean_squared_error: 4.5973 - val_mean_absolute_error: 1.7493\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 848us/step - loss: 4.3178 - mean_squared_error: 4.3178 - mean_absolute_error: 1.5566 - val_loss: 3.8581 - val_mean_squared_error: 3.8581 - val_mean_absolute_error: 1.5791\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 849us/step - loss: 3.3534 - mean_squared_error: 3.3534 - mean_absolute_error: 1.3664 - val_loss: 3.6593 - val_mean_squared_error: 3.6593 - val_mean_absolute_error: 1.5278\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 2.6789 - mean_squared_error: 2.6789 - mean_absolute_error: 1.2078 - val_loss: 1.6180 - val_mean_squared_error: 1.6180 - val_mean_absolute_error: 1.0427\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 2.3211 - mean_squared_error: 2.3211 - mean_absolute_error: 1.1421 - val_loss: 1.9178 - val_mean_squared_error: 1.9178 - val_mean_absolute_error: 1.0315\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 851us/step - loss: 1.9136 - mean_squared_error: 1.9136 - mean_absolute_error: 1.0109 - val_loss: 5.1057 - val_mean_squared_error: 5.1057 - val_mean_absolute_error: 1.7906\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 848us/step - loss: 1.5668 - mean_squared_error: 1.5668 - mean_absolute_error: 0.9223 - val_loss: 0.6617 - val_mean_squared_error: 0.6617 - val_mean_absolute_error: 0.6566\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 1.3015 - mean_squared_error: 1.3015 - mean_absolute_error: 0.8375 - val_loss: 2.9964 - val_mean_squared_error: 2.9964 - val_mean_absolute_error: 1.1988\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 1.2095 - mean_squared_error: 1.2095 - mean_absolute_error: 0.8041 - val_loss: 0.7343 - val_mean_squared_error: 0.7343 - val_mean_absolute_error: 0.6667\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 839us/step - loss: 1.1879 - mean_squared_error: 1.1879 - mean_absolute_error: 0.8061 - val_loss: 0.6768 - val_mean_squared_error: 0.6768 - val_mean_absolute_error: 0.5973\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.2909 - mean_squared_error: 1.2909 - mean_absolute_error: 0.8422 - val_loss: 1.2814 - val_mean_squared_error: 1.2814 - val_mean_absolute_error: 0.8967\n",
      "Epoch 16/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 1.3383 - mean_squared_error: 1.3383 - mean_absolute_error: 0.8478 - val_loss: 1.3912 - val_mean_squared_error: 1.3912 - val_mean_absolute_error: 0.9427\n",
      "10/10 - 0s - loss: 0.6617 - mean_squared_error: 0.6617 - mean_absolute_error: 0.6566 - 15ms/epoch - 2ms/step\n",
      "Test MSE: 0.6616790294647217    Test MAE: 0.6566362977027893  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "677/677 [==============================] - 1s 934us/step - loss: 7240.7642 - mean_squared_error: 7240.7642 - mean_absolute_error: 76.4381 - val_loss: 1765.7739 - val_mean_squared_error: 1765.7739 - val_mean_absolute_error: 38.5037\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 591.1028 - mean_squared_error: 591.1028 - mean_absolute_error: 19.5133 - val_loss: 121.2357 - val_mean_squared_error: 121.2357 - val_mean_absolute_error: 9.1283\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 45.3468 - mean_squared_error: 45.3468 - mean_absolute_error: 5.2132 - val_loss: 18.8843 - val_mean_squared_error: 18.8843 - val_mean_absolute_error: 3.6315\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 10.8575 - mean_squared_error: 10.8575 - mean_absolute_error: 2.6058 - val_loss: 7.1885 - val_mean_squared_error: 7.1885 - val_mean_absolute_error: 2.1814\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 848us/step - loss: 6.1003 - mean_squared_error: 6.1003 - mean_absolute_error: 1.8948 - val_loss: 3.9315 - val_mean_squared_error: 3.9315 - val_mean_absolute_error: 1.6318\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 4.2016 - mean_squared_error: 4.2016 - mean_absolute_error: 1.5459 - val_loss: 3.7206 - val_mean_squared_error: 3.7206 - val_mean_absolute_error: 1.5479\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 844us/step - loss: 3.2535 - mean_squared_error: 3.2535 - mean_absolute_error: 1.3499 - val_loss: 2.5828 - val_mean_squared_error: 2.5828 - val_mean_absolute_error: 1.3326\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 837us/step - loss: 2.7739 - mean_squared_error: 2.7739 - mean_absolute_error: 1.2300 - val_loss: 1.9041 - val_mean_squared_error: 1.9041 - val_mean_absolute_error: 1.1544\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 2.3567 - mean_squared_error: 2.3567 - mean_absolute_error: 1.1137 - val_loss: 2.3175 - val_mean_squared_error: 2.3175 - val_mean_absolute_error: 1.2114\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 2.0067 - mean_squared_error: 2.0067 - mean_absolute_error: 1.0446 - val_loss: 1.5270 - val_mean_squared_error: 1.5270 - val_mean_absolute_error: 1.0191\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.5545 - mean_squared_error: 1.5545 - mean_absolute_error: 0.9141 - val_loss: 0.8889 - val_mean_squared_error: 0.8889 - val_mean_absolute_error: 0.7637\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 1.3613 - mean_squared_error: 1.3613 - mean_absolute_error: 0.8578 - val_loss: 0.8533 - val_mean_squared_error: 0.8533 - val_mean_absolute_error: 0.7418\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 1.2759 - mean_squared_error: 1.2759 - mean_absolute_error: 0.8334 - val_loss: 0.9593 - val_mean_squared_error: 0.9593 - val_mean_absolute_error: 0.7870\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 851us/step - loss: 1.1180 - mean_squared_error: 1.1180 - mean_absolute_error: 0.7824 - val_loss: 2.0858 - val_mean_squared_error: 2.0858 - val_mean_absolute_error: 1.2476\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 1.0752 - mean_squared_error: 1.0752 - mean_absolute_error: 0.7741 - val_loss: 1.0701 - val_mean_squared_error: 1.0701 - val_mean_absolute_error: 0.8410\n",
      "Epoch 16/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 1.1117 - mean_squared_error: 1.1117 - mean_absolute_error: 0.7890 - val_loss: 0.9179 - val_mean_squared_error: 0.9179 - val_mean_absolute_error: 0.7707\n",
      "Epoch 17/300\n",
      "677/677 [==============================] - 1s 844us/step - loss: 1.1868 - mean_squared_error: 1.1868 - mean_absolute_error: 0.8229 - val_loss: 0.7341 - val_mean_squared_error: 0.7341 - val_mean_absolute_error: 0.6711\n",
      "Epoch 18/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 1.0672 - mean_squared_error: 1.0672 - mean_absolute_error: 0.7710 - val_loss: 0.8699 - val_mean_squared_error: 0.8699 - val_mean_absolute_error: 0.7432\n",
      "Epoch 19/300\n",
      "677/677 [==============================] - 1s 848us/step - loss: 1.1366 - mean_squared_error: 1.1366 - mean_absolute_error: 0.7950 - val_loss: 1.0056 - val_mean_squared_error: 1.0056 - val_mean_absolute_error: 0.8094\n",
      "Epoch 20/300\n",
      "677/677 [==============================] - 1s 854us/step - loss: 0.9865 - mean_squared_error: 0.9865 - mean_absolute_error: 0.7444 - val_loss: 0.6046 - val_mean_squared_error: 0.6046 - val_mean_absolute_error: 0.6196\n",
      "Epoch 21/300\n",
      "677/677 [==============================] - 1s 836us/step - loss: 1.0025 - mean_squared_error: 1.0025 - mean_absolute_error: 0.7650 - val_loss: 0.6885 - val_mean_squared_error: 0.6885 - val_mean_absolute_error: 0.6708\n",
      "Epoch 22/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 0.9407 - mean_squared_error: 0.9407 - mean_absolute_error: 0.7204 - val_loss: 0.6433 - val_mean_squared_error: 0.6433 - val_mean_absolute_error: 0.6379\n",
      "Epoch 23/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.0652 - mean_squared_error: 1.0652 - mean_absolute_error: 0.7743 - val_loss: 0.6382 - val_mean_squared_error: 0.6382 - val_mean_absolute_error: 0.6398\n",
      "Epoch 24/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 0.9023 - mean_squared_error: 0.9023 - mean_absolute_error: 0.7126 - val_loss: 0.9128 - val_mean_squared_error: 0.9128 - val_mean_absolute_error: 0.7574\n",
      "Epoch 25/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 0.9240 - mean_squared_error: 0.9240 - mean_absolute_error: 0.7294 - val_loss: 0.5732 - val_mean_squared_error: 0.5732 - val_mean_absolute_error: 0.5911\n",
      "Epoch 26/300\n",
      "677/677 [==============================] - 1s 857us/step - loss: 1.0449 - mean_squared_error: 1.0449 - mean_absolute_error: 0.7856 - val_loss: 1.0744 - val_mean_squared_error: 1.0744 - val_mean_absolute_error: 0.8210\n",
      "Epoch 27/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 0.9009 - mean_squared_error: 0.9009 - mean_absolute_error: 0.7221 - val_loss: 0.7462 - val_mean_squared_error: 0.7462 - val_mean_absolute_error: 0.6979\n",
      "Epoch 28/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 0.8789 - mean_squared_error: 0.8789 - mean_absolute_error: 0.7180 - val_loss: 0.9261 - val_mean_squared_error: 0.9261 - val_mean_absolute_error: 0.7928\n",
      "Epoch 29/300\n",
      "677/677 [==============================] - 1s 841us/step - loss: 1.0154 - mean_squared_error: 1.0154 - mean_absolute_error: 0.7686 - val_loss: 1.0254 - val_mean_squared_error: 1.0254 - val_mean_absolute_error: 0.8050\n",
      "Epoch 30/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 0.8474 - mean_squared_error: 0.8474 - mean_absolute_error: 0.7143 - val_loss: 1.2815 - val_mean_squared_error: 1.2815 - val_mean_absolute_error: 0.9419\n",
      "10/10 - 0s - loss: 0.5732 - mean_squared_error: 0.5732 - mean_absolute_error: 0.5911 - 16ms/epoch - 2ms/step\n",
      "Test MSE: 0.5731725096702576    Test MAE: 0.5910996198654175  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "677/677 [==============================] - 1s 930us/step - loss: 7323.5815 - mean_squared_error: 7323.5815 - mean_absolute_error: 76.7027 - val_loss: 1700.5350 - val_mean_squared_error: 1700.5350 - val_mean_absolute_error: 37.7403\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 854us/step - loss: 608.4700 - mean_squared_error: 608.4700 - mean_absolute_error: 19.6884 - val_loss: 108.2003 - val_mean_squared_error: 108.2003 - val_mean_absolute_error: 8.1261\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 44.9875 - mean_squared_error: 44.9875 - mean_absolute_error: 5.1467 - val_loss: 20.9866 - val_mean_squared_error: 20.9866 - val_mean_absolute_error: 3.9257\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 841us/step - loss: 10.7231 - mean_squared_error: 10.7231 - mean_absolute_error: 2.5606 - val_loss: 11.6127 - val_mean_squared_error: 11.6127 - val_mean_absolute_error: 2.8034\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 6.1548 - mean_squared_error: 6.1548 - mean_absolute_error: 1.9092 - val_loss: 5.9421 - val_mean_squared_error: 5.9421 - val_mean_absolute_error: 1.9016\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 4.5435 - mean_squared_error: 4.5435 - mean_absolute_error: 1.6203 - val_loss: 3.4999 - val_mean_squared_error: 3.4999 - val_mean_absolute_error: 1.4782\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 3.5596 - mean_squared_error: 3.5596 - mean_absolute_error: 1.4242 - val_loss: 2.1845 - val_mean_squared_error: 2.1845 - val_mean_absolute_error: 1.1736\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 844us/step - loss: 2.8779 - mean_squared_error: 2.8779 - mean_absolute_error: 1.2576 - val_loss: 2.5479 - val_mean_squared_error: 2.5479 - val_mean_absolute_error: 1.2238\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 855us/step - loss: 2.4058 - mean_squared_error: 2.4058 - mean_absolute_error: 1.1614 - val_loss: 1.7034 - val_mean_squared_error: 1.7034 - val_mean_absolute_error: 0.9286\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 853us/step - loss: 1.8587 - mean_squared_error: 1.8587 - mean_absolute_error: 1.0059 - val_loss: 1.3391 - val_mean_squared_error: 1.3391 - val_mean_absolute_error: 0.8761\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 839us/step - loss: 1.6410 - mean_squared_error: 1.6410 - mean_absolute_error: 0.9556 - val_loss: 2.0888 - val_mean_squared_error: 2.0888 - val_mean_absolute_error: 1.0246\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 849us/step - loss: 1.3613 - mean_squared_error: 1.3613 - mean_absolute_error: 0.8767 - val_loss: 0.8908 - val_mean_squared_error: 0.8908 - val_mean_absolute_error: 0.7232\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 1.3583 - mean_squared_error: 1.3583 - mean_absolute_error: 0.8440 - val_loss: 1.9424 - val_mean_squared_error: 1.9424 - val_mean_absolute_error: 1.0901\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 849us/step - loss: 1.1069 - mean_squared_error: 1.1069 - mean_absolute_error: 0.7960 - val_loss: 1.4263 - val_mean_squared_error: 1.4263 - val_mean_absolute_error: 0.9344\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 854us/step - loss: 1.2076 - mean_squared_error: 1.2076 - mean_absolute_error: 0.8246 - val_loss: 2.3547 - val_mean_squared_error: 2.3547 - val_mean_absolute_error: 1.3424\n",
      "Epoch 16/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.0307 - mean_squared_error: 1.0307 - mean_absolute_error: 0.7663 - val_loss: 1.4982 - val_mean_squared_error: 1.4982 - val_mean_absolute_error: 1.0069\n",
      "Epoch 17/300\n",
      "677/677 [==============================] - 1s 849us/step - loss: 1.0696 - mean_squared_error: 1.0696 - mean_absolute_error: 0.7797 - val_loss: 0.8118 - val_mean_squared_error: 0.8118 - val_mean_absolute_error: 0.7051\n",
      "Epoch 18/300\n",
      "677/677 [==============================] - 1s 844us/step - loss: 0.9783 - mean_squared_error: 0.9783 - mean_absolute_error: 0.7488 - val_loss: 0.6964 - val_mean_squared_error: 0.6964 - val_mean_absolute_error: 0.6126\n",
      "Epoch 19/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 0.9790 - mean_squared_error: 0.9790 - mean_absolute_error: 0.7524 - val_loss: 2.8598 - val_mean_squared_error: 2.8598 - val_mean_absolute_error: 1.4426\n",
      "Epoch 20/300\n",
      "677/677 [==============================] - 1s 849us/step - loss: 1.0691 - mean_squared_error: 1.0691 - mean_absolute_error: 0.7956 - val_loss: 2.2964 - val_mean_squared_error: 2.2964 - val_mean_absolute_error: 1.3206\n",
      "Epoch 21/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 1.1330 - mean_squared_error: 1.1330 - mean_absolute_error: 0.8032 - val_loss: 0.9279 - val_mean_squared_error: 0.9279 - val_mean_absolute_error: 0.7412\n",
      "Epoch 22/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 0.9956 - mean_squared_error: 0.9956 - mean_absolute_error: 0.7529 - val_loss: 2.5088 - val_mean_squared_error: 2.5088 - val_mean_absolute_error: 1.4232\n",
      "Epoch 23/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 1.0901 - mean_squared_error: 1.0901 - mean_absolute_error: 0.7944 - val_loss: 0.6164 - val_mean_squared_error: 0.6164 - val_mean_absolute_error: 0.5861\n",
      "Epoch 24/300\n",
      "677/677 [==============================] - 1s 839us/step - loss: 0.9192 - mean_squared_error: 0.9192 - mean_absolute_error: 0.7339 - val_loss: 0.5838 - val_mean_squared_error: 0.5838 - val_mean_absolute_error: 0.5868\n",
      "Epoch 25/300\n",
      "677/677 [==============================] - 1s 838us/step - loss: 0.9554 - mean_squared_error: 0.9554 - mean_absolute_error: 0.7451 - val_loss: 0.7641 - val_mean_squared_error: 0.7641 - val_mean_absolute_error: 0.6654\n",
      "Epoch 26/300\n",
      "677/677 [==============================] - 1s 849us/step - loss: 0.9644 - mean_squared_error: 0.9644 - mean_absolute_error: 0.7486 - val_loss: 0.7140 - val_mean_squared_error: 0.7140 - val_mean_absolute_error: 0.6438\n",
      "Epoch 27/300\n",
      "677/677 [==============================] - 1s 844us/step - loss: 0.9285 - mean_squared_error: 0.9285 - mean_absolute_error: 0.7322 - val_loss: 1.0050 - val_mean_squared_error: 1.0050 - val_mean_absolute_error: 0.7897\n",
      "Epoch 28/300\n",
      "677/677 [==============================] - 1s 866us/step - loss: 1.1869 - mean_squared_error: 1.1869 - mean_absolute_error: 0.8059 - val_loss: 0.5933 - val_mean_squared_error: 0.5933 - val_mean_absolute_error: 0.5722\n",
      "Epoch 29/300\n",
      "677/677 [==============================] - 1s 851us/step - loss: 0.8793 - mean_squared_error: 0.8793 - mean_absolute_error: 0.7261 - val_loss: 1.3194 - val_mean_squared_error: 1.3194 - val_mean_absolute_error: 0.9424\n",
      "10/10 - 0s - loss: 0.5838 - mean_squared_error: 0.5838 - mean_absolute_error: 0.5868 - 16ms/epoch - 2ms/step\n",
      "Test MSE: 0.5837678909301758    Test MAE: 0.5868251323699951  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "677/677 [==============================] - 1s 927us/step - loss: 7166.8145 - mean_squared_error: 7166.8145 - mean_absolute_error: 75.9559 - val_loss: 1702.5927 - val_mean_squared_error: 1702.5927 - val_mean_absolute_error: 37.6555\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 570.7310 - mean_squared_error: 570.7310 - mean_absolute_error: 18.9500 - val_loss: 102.8626 - val_mean_squared_error: 102.8626 - val_mean_absolute_error: 8.1308\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 848us/step - loss: 42.2010 - mean_squared_error: 42.2010 - mean_absolute_error: 4.9576 - val_loss: 17.2472 - val_mean_squared_error: 17.2472 - val_mean_absolute_error: 3.3642\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 10.3533 - mean_squared_error: 10.3533 - mean_absolute_error: 2.5102 - val_loss: 6.5867 - val_mean_squared_error: 6.5867 - val_mean_absolute_error: 2.1196\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 5.7322 - mean_squared_error: 5.7322 - mean_absolute_error: 1.8446 - val_loss: 3.5537 - val_mean_squared_error: 3.5537 - val_mean_absolute_error: 1.5585\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 4.2524 - mean_squared_error: 4.2524 - mean_absolute_error: 1.5534 - val_loss: 2.8106 - val_mean_squared_error: 2.8106 - val_mean_absolute_error: 1.3620\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 853us/step - loss: 3.3687 - mean_squared_error: 3.3687 - mean_absolute_error: 1.3689 - val_loss: 3.5283 - val_mean_squared_error: 3.5283 - val_mean_absolute_error: 1.2820\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 854us/step - loss: 2.8105 - mean_squared_error: 2.8105 - mean_absolute_error: 1.2495 - val_loss: 1.4969 - val_mean_squared_error: 1.4969 - val_mean_absolute_error: 0.9910\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 844us/step - loss: 2.1724 - mean_squared_error: 2.1724 - mean_absolute_error: 1.0986 - val_loss: 1.5533 - val_mean_squared_error: 1.5533 - val_mean_absolute_error: 0.9820\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 838us/step - loss: 1.8828 - mean_squared_error: 1.8828 - mean_absolute_error: 1.0139 - val_loss: 1.1693 - val_mean_squared_error: 1.1693 - val_mean_absolute_error: 0.8494\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 1.3838 - mean_squared_error: 1.3838 - mean_absolute_error: 0.8729 - val_loss: 2.1021 - val_mean_squared_error: 2.1021 - val_mean_absolute_error: 1.2438\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 1.4635 - mean_squared_error: 1.4635 - mean_absolute_error: 0.8950 - val_loss: 0.8787 - val_mean_squared_error: 0.8787 - val_mean_absolute_error: 0.7367\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 854us/step - loss: 1.1642 - mean_squared_error: 1.1642 - mean_absolute_error: 0.8061 - val_loss: 0.9368 - val_mean_squared_error: 0.9368 - val_mean_absolute_error: 0.7871\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 1.2110 - mean_squared_error: 1.2110 - mean_absolute_error: 0.8287 - val_loss: 1.1515 - val_mean_squared_error: 1.1515 - val_mean_absolute_error: 0.8468\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 1.1352 - mean_squared_error: 1.1352 - mean_absolute_error: 0.7902 - val_loss: 0.9098 - val_mean_squared_error: 0.9098 - val_mean_absolute_error: 0.7264\n",
      "Epoch 16/300\n",
      "677/677 [==============================] - 1s 853us/step - loss: 1.0433 - mean_squared_error: 1.0433 - mean_absolute_error: 0.7679 - val_loss: 0.5188 - val_mean_squared_error: 0.5188 - val_mean_absolute_error: 0.5634\n",
      "Epoch 17/300\n",
      "677/677 [==============================] - 1s 851us/step - loss: 1.1670 - mean_squared_error: 1.1670 - mean_absolute_error: 0.8217 - val_loss: 0.5528 - val_mean_squared_error: 0.5528 - val_mean_absolute_error: 0.5831\n",
      "Epoch 18/300\n",
      "677/677 [==============================] - 1s 849us/step - loss: 0.9441 - mean_squared_error: 0.9441 - mean_absolute_error: 0.7323 - val_loss: 0.4888 - val_mean_squared_error: 0.4888 - val_mean_absolute_error: 0.5614\n",
      "Epoch 19/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 1.0267 - mean_squared_error: 1.0267 - mean_absolute_error: 0.7674 - val_loss: 1.2551 - val_mean_squared_error: 1.2551 - val_mean_absolute_error: 0.9075\n",
      "Epoch 20/300\n",
      "677/677 [==============================] - 1s 856us/step - loss: 1.0469 - mean_squared_error: 1.0469 - mean_absolute_error: 0.7866 - val_loss: 1.0976 - val_mean_squared_error: 1.0976 - val_mean_absolute_error: 0.8630\n",
      "Epoch 21/300\n",
      "677/677 [==============================] - 1s 854us/step - loss: 0.9640 - mean_squared_error: 0.9640 - mean_absolute_error: 0.7448 - val_loss: 0.6918 - val_mean_squared_error: 0.6918 - val_mean_absolute_error: 0.6943\n",
      "Epoch 22/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 0.9788 - mean_squared_error: 0.9788 - mean_absolute_error: 0.7568 - val_loss: 0.6556 - val_mean_squared_error: 0.6556 - val_mean_absolute_error: 0.6657\n",
      "Epoch 23/300\n",
      "677/677 [==============================] - 1s 852us/step - loss: 1.1192 - mean_squared_error: 1.1192 - mean_absolute_error: 0.8066 - val_loss: 0.6447 - val_mean_squared_error: 0.6447 - val_mean_absolute_error: 0.6490\n",
      "10/10 - 0s - loss: 0.4888 - mean_squared_error: 0.4888 - mean_absolute_error: 0.5614 - 15ms/epoch - 2ms/step\n",
      "Test MSE: 0.48878398537635803    Test MAE: 0.5614268183708191  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "677/677 [==============================] - 1s 930us/step - loss: 7230.2168 - mean_squared_error: 7230.2168 - mean_absolute_error: 76.4928 - val_loss: 1579.4054 - val_mean_squared_error: 1579.4054 - val_mean_absolute_error: 35.7842\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 562.0564 - mean_squared_error: 562.0564 - mean_absolute_error: 18.7629 - val_loss: 102.4735 - val_mean_squared_error: 102.4735 - val_mean_absolute_error: 7.6699\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 42.2744 - mean_squared_error: 42.2744 - mean_absolute_error: 4.9888 - val_loss: 14.9383 - val_mean_squared_error: 14.9383 - val_mean_absolute_error: 3.0904\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 849us/step - loss: 10.4560 - mean_squared_error: 10.4560 - mean_absolute_error: 2.5480 - val_loss: 5.7254 - val_mean_squared_error: 5.7254 - val_mean_absolute_error: 1.9783\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 839us/step - loss: 5.5798 - mean_squared_error: 5.5798 - mean_absolute_error: 1.7981 - val_loss: 3.3577 - val_mean_squared_error: 3.3577 - val_mean_absolute_error: 1.4895\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 3.9650 - mean_squared_error: 3.9650 - mean_absolute_error: 1.5366 - val_loss: 2.6775 - val_mean_squared_error: 2.6775 - val_mean_absolute_error: 1.3212\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 3.2140 - mean_squared_error: 3.2140 - mean_absolute_error: 1.3503 - val_loss: 1.8610 - val_mean_squared_error: 1.8610 - val_mean_absolute_error: 1.0832\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 839us/step - loss: 2.5765 - mean_squared_error: 2.5765 - mean_absolute_error: 1.2044 - val_loss: 5.4735 - val_mean_squared_error: 5.4735 - val_mean_absolute_error: 1.9304\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 2.1398 - mean_squared_error: 2.1398 - mean_absolute_error: 1.0973 - val_loss: 1.0617 - val_mean_squared_error: 1.0617 - val_mean_absolute_error: 0.8312\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.8824 - mean_squared_error: 1.8824 - mean_absolute_error: 1.0279 - val_loss: 2.2140 - val_mean_squared_error: 2.2140 - val_mean_absolute_error: 1.2313\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 853us/step - loss: 1.4851 - mean_squared_error: 1.4851 - mean_absolute_error: 0.9090 - val_loss: 1.2040 - val_mean_squared_error: 1.2040 - val_mean_absolute_error: 0.8953\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 1.3612 - mean_squared_error: 1.3612 - mean_absolute_error: 0.8739 - val_loss: 0.9782 - val_mean_squared_error: 0.9782 - val_mean_absolute_error: 0.8018\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 848us/step - loss: 1.2139 - mean_squared_error: 1.2139 - mean_absolute_error: 0.8370 - val_loss: 0.7021 - val_mean_squared_error: 0.7021 - val_mean_absolute_error: 0.6834\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 1.3560 - mean_squared_error: 1.3560 - mean_absolute_error: 0.8793 - val_loss: 0.5138 - val_mean_squared_error: 0.5138 - val_mean_absolute_error: 0.5897\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 853us/step - loss: 1.2917 - mean_squared_error: 1.2917 - mean_absolute_error: 0.8586 - val_loss: 0.7442 - val_mean_squared_error: 0.7442 - val_mean_absolute_error: 0.7009\n",
      "Epoch 16/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 1.0176 - mean_squared_error: 1.0176 - mean_absolute_error: 0.7564 - val_loss: 0.8028 - val_mean_squared_error: 0.8028 - val_mean_absolute_error: 0.7297\n",
      "Epoch 17/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 1.1254 - mean_squared_error: 1.1254 - mean_absolute_error: 0.7955 - val_loss: 0.8391 - val_mean_squared_error: 0.8391 - val_mean_absolute_error: 0.7377\n",
      "Epoch 18/300\n",
      "677/677 [==============================] - 1s 848us/step - loss: 1.0317 - mean_squared_error: 1.0317 - mean_absolute_error: 0.7855 - val_loss: 1.2968 - val_mean_squared_error: 1.2968 - val_mean_absolute_error: 0.9358\n",
      "Epoch 19/300\n",
      "677/677 [==============================] - 1s 853us/step - loss: 1.1655 - mean_squared_error: 1.1655 - mean_absolute_error: 0.8169 - val_loss: 0.5805 - val_mean_squared_error: 0.5805 - val_mean_absolute_error: 0.6181\n",
      "10/10 - 0s - loss: 0.5138 - mean_squared_error: 0.5138 - mean_absolute_error: 0.5896 - 16ms/epoch - 2ms/step\n",
      "Test MSE: 0.5137947797775269    Test MAE: 0.5896469950675964  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "677/677 [==============================] - 1s 912us/step - loss: 7071.1128 - mean_squared_error: 7071.1128 - mean_absolute_error: 75.5355 - val_loss: 1639.3419 - val_mean_squared_error: 1639.3419 - val_mean_absolute_error: 37.5109\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 837us/step - loss: 569.0168 - mean_squared_error: 569.0168 - mean_absolute_error: 18.9146 - val_loss: 102.6907 - val_mean_squared_error: 102.6907 - val_mean_absolute_error: 7.9391\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 39.3519 - mean_squared_error: 39.3519 - mean_absolute_error: 4.7767 - val_loss: 24.2556 - val_mean_squared_error: 24.2556 - val_mean_absolute_error: 3.7786\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 850us/step - loss: 8.8773 - mean_squared_error: 8.8773 - mean_absolute_error: 2.4069 - val_loss: 10.9269 - val_mean_squared_error: 10.9269 - val_mean_absolute_error: 1.9910\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 829us/step - loss: 4.7319 - mean_squared_error: 4.7319 - mean_absolute_error: 1.7494 - val_loss: 8.1879 - val_mean_squared_error: 8.1879 - val_mean_absolute_error: 1.6189\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 828us/step - loss: 3.4423 - mean_squared_error: 3.4423 - mean_absolute_error: 1.4790 - val_loss: 6.5209 - val_mean_squared_error: 6.5209 - val_mean_absolute_error: 1.3593\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 828us/step - loss: 2.7772 - mean_squared_error: 2.7772 - mean_absolute_error: 1.3337 - val_loss: 5.9096 - val_mean_squared_error: 5.9096 - val_mean_absolute_error: 1.3084\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 839us/step - loss: 2.4684 - mean_squared_error: 2.4684 - mean_absolute_error: 1.2509 - val_loss: 4.8267 - val_mean_squared_error: 4.8267 - val_mean_absolute_error: 1.1202\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 841us/step - loss: 2.0554 - mean_squared_error: 2.0554 - mean_absolute_error: 1.1268 - val_loss: 4.2193 - val_mean_squared_error: 4.2193 - val_mean_absolute_error: 1.0399\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.7115 - mean_squared_error: 1.7115 - mean_absolute_error: 1.0246 - val_loss: 3.7557 - val_mean_squared_error: 3.7557 - val_mean_absolute_error: 1.0155\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 833us/step - loss: 1.5106 - mean_squared_error: 1.5106 - mean_absolute_error: 0.9628 - val_loss: 2.6731 - val_mean_squared_error: 2.6731 - val_mean_absolute_error: 0.8217\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 833us/step - loss: 1.1423 - mean_squared_error: 1.1423 - mean_absolute_error: 0.8394 - val_loss: 2.1883 - val_mean_squared_error: 2.1883 - val_mean_absolute_error: 0.7157\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 830us/step - loss: 1.1701 - mean_squared_error: 1.1701 - mean_absolute_error: 0.8408 - val_loss: 2.2401 - val_mean_squared_error: 2.2401 - val_mean_absolute_error: 0.8091\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 835us/step - loss: 1.1041 - mean_squared_error: 1.1041 - mean_absolute_error: 0.8110 - val_loss: 2.5263 - val_mean_squared_error: 2.5263 - val_mean_absolute_error: 0.9877\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 836us/step - loss: 1.1408 - mean_squared_error: 1.1408 - mean_absolute_error: 0.8239 - val_loss: 2.4109 - val_mean_squared_error: 2.4109 - val_mean_absolute_error: 0.8426\n",
      "Epoch 16/300\n",
      "677/677 [==============================] - 1s 841us/step - loss: 0.9708 - mean_squared_error: 0.9708 - mean_absolute_error: 0.7662 - val_loss: 1.6397 - val_mean_squared_error: 1.6397 - val_mean_absolute_error: 0.6575\n",
      "Epoch 17/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.0188 - mean_squared_error: 1.0188 - mean_absolute_error: 0.7902 - val_loss: 1.6881 - val_mean_squared_error: 1.6881 - val_mean_absolute_error: 0.6897\n",
      "Epoch 18/300\n",
      "677/677 [==============================] - 1s 825us/step - loss: 0.9784 - mean_squared_error: 0.9784 - mean_absolute_error: 0.7695 - val_loss: 3.0305 - val_mean_squared_error: 3.0305 - val_mean_absolute_error: 1.3654\n",
      "Epoch 19/300\n",
      "677/677 [==============================] - 1s 837us/step - loss: 0.9924 - mean_squared_error: 0.9924 - mean_absolute_error: 0.7713 - val_loss: 1.9195 - val_mean_squared_error: 1.9195 - val_mean_absolute_error: 0.8084\n",
      "Epoch 20/300\n",
      "677/677 [==============================] - 1s 839us/step - loss: 0.9511 - mean_squared_error: 0.9511 - mean_absolute_error: 0.7649 - val_loss: 1.7787 - val_mean_squared_error: 1.7787 - val_mean_absolute_error: 0.7883\n",
      "Epoch 21/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 1.0434 - mean_squared_error: 1.0434 - mean_absolute_error: 0.7914 - val_loss: 1.8675 - val_mean_squared_error: 1.8675 - val_mean_absolute_error: 0.8413\n",
      "10/10 - 0s - loss: 1.6397 - mean_squared_error: 1.6397 - mean_absolute_error: 0.6575 - 59ms/epoch - 6ms/step\n",
      "Test MSE: 1.6396701335906982    Test MAE: 0.6574565172195435  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "677/677 [==============================] - 1s 921us/step - loss: 7228.1987 - mean_squared_error: 7228.1987 - mean_absolute_error: 76.5394 - val_loss: 1643.7596 - val_mean_squared_error: 1643.7596 - val_mean_absolute_error: 36.9547\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 836us/step - loss: 574.9755 - mean_squared_error: 574.9755 - mean_absolute_error: 19.0453 - val_loss: 102.8019 - val_mean_squared_error: 102.8019 - val_mean_absolute_error: 8.2773\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 43.3000 - mean_squared_error: 43.3000 - mean_absolute_error: 5.0747 - val_loss: 15.7681 - val_mean_squared_error: 15.7681 - val_mean_absolute_error: 3.2981\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 836us/step - loss: 10.2572 - mean_squared_error: 10.2572 - mean_absolute_error: 2.5063 - val_loss: 5.4901 - val_mean_squared_error: 5.4901 - val_mean_absolute_error: 1.9448\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 5.7349 - mean_squared_error: 5.7349 - mean_absolute_error: 1.8263 - val_loss: 3.8842 - val_mean_squared_error: 3.8842 - val_mean_absolute_error: 1.6039\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 835us/step - loss: 4.1284 - mean_squared_error: 4.1284 - mean_absolute_error: 1.5434 - val_loss: 3.0685 - val_mean_squared_error: 3.0685 - val_mean_absolute_error: 1.4360\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 830us/step - loss: 3.3584 - mean_squared_error: 3.3584 - mean_absolute_error: 1.3736 - val_loss: 2.0494 - val_mean_squared_error: 2.0494 - val_mean_absolute_error: 1.1780\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 849us/step - loss: 2.8056 - mean_squared_error: 2.8056 - mean_absolute_error: 1.2553 - val_loss: 2.4410 - val_mean_squared_error: 2.4410 - val_mean_absolute_error: 1.2586\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 838us/step - loss: 2.1075 - mean_squared_error: 2.1075 - mean_absolute_error: 1.0790 - val_loss: 1.4236 - val_mean_squared_error: 1.4236 - val_mean_absolute_error: 0.9599\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 2.1616 - mean_squared_error: 2.1616 - mean_absolute_error: 1.0738 - val_loss: 0.9322 - val_mean_squared_error: 0.9322 - val_mean_absolute_error: 0.7671\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 1.4814 - mean_squared_error: 1.4814 - mean_absolute_error: 0.8951 - val_loss: 1.8121 - val_mean_squared_error: 1.8121 - val_mean_absolute_error: 1.0967\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 857us/step - loss: 1.3317 - mean_squared_error: 1.3317 - mean_absolute_error: 0.8625 - val_loss: 0.6993 - val_mean_squared_error: 0.6993 - val_mean_absolute_error: 0.6744\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 827us/step - loss: 1.1475 - mean_squared_error: 1.1475 - mean_absolute_error: 0.7965 - val_loss: 1.0800 - val_mean_squared_error: 1.0800 - val_mean_absolute_error: 0.8337\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 1.1159 - mean_squared_error: 1.1159 - mean_absolute_error: 0.7974 - val_loss: 0.7292 - val_mean_squared_error: 0.7292 - val_mean_absolute_error: 0.6802\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 1.1820 - mean_squared_error: 1.1820 - mean_absolute_error: 0.8246 - val_loss: 1.1003 - val_mean_squared_error: 1.1003 - val_mean_absolute_error: 0.8564\n",
      "Epoch 16/300\n",
      "677/677 [==============================] - 1s 847us/step - loss: 1.1438 - mean_squared_error: 1.1438 - mean_absolute_error: 0.8114 - val_loss: 0.7982 - val_mean_squared_error: 0.7982 - val_mean_absolute_error: 0.7054\n",
      "Epoch 17/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 1.0378 - mean_squared_error: 1.0378 - mean_absolute_error: 0.7549 - val_loss: 0.9841 - val_mean_squared_error: 0.9841 - val_mean_absolute_error: 0.7993\n",
      "10/10 - 0s - loss: 0.6993 - mean_squared_error: 0.6993 - mean_absolute_error: 0.6744 - 57ms/epoch - 6ms/step\n",
      "Test MSE: 0.6992541551589966    Test MAE: 0.6743720173835754  \n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 130)               910       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 140)               18340     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 141       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,391\n",
      "Trainable params: 19,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "677/677 [==============================] - 1s 929us/step - loss: 7265.1221 - mean_squared_error: 7265.1221 - mean_absolute_error: 76.7562 - val_loss: 1678.9956 - val_mean_squared_error: 1678.9956 - val_mean_absolute_error: 37.1580\n",
      "Epoch 2/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 555.7524 - mean_squared_error: 555.7524 - mean_absolute_error: 18.5900 - val_loss: 105.5886 - val_mean_squared_error: 105.5886 - val_mean_absolute_error: 8.0326\n",
      "Epoch 3/300\n",
      "677/677 [==============================] - 1s 841us/step - loss: 42.4039 - mean_squared_error: 42.4039 - mean_absolute_error: 4.9720 - val_loss: 16.0880 - val_mean_squared_error: 16.0880 - val_mean_absolute_error: 3.2999\n",
      "Epoch 4/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 10.2859 - mean_squared_error: 10.2859 - mean_absolute_error: 2.5224 - val_loss: 6.6797 - val_mean_squared_error: 6.6797 - val_mean_absolute_error: 2.1434\n",
      "Epoch 5/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 5.4611 - mean_squared_error: 5.4611 - mean_absolute_error: 1.8029 - val_loss: 4.1325 - val_mean_squared_error: 4.1325 - val_mean_absolute_error: 1.6597\n",
      "Epoch 6/300\n",
      "677/677 [==============================] - 1s 845us/step - loss: 4.0922 - mean_squared_error: 4.0922 - mean_absolute_error: 1.5258 - val_loss: 3.5616 - val_mean_squared_error: 3.5616 - val_mean_absolute_error: 1.5157\n",
      "Epoch 7/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 3.4038 - mean_squared_error: 3.4038 - mean_absolute_error: 1.3775 - val_loss: 2.4111 - val_mean_squared_error: 2.4111 - val_mean_absolute_error: 1.2566\n",
      "Epoch 8/300\n",
      "677/677 [==============================] - 1s 846us/step - loss: 2.6986 - mean_squared_error: 2.6986 - mean_absolute_error: 1.2268 - val_loss: 1.8262 - val_mean_squared_error: 1.8262 - val_mean_absolute_error: 1.1012\n",
      "Epoch 9/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 2.2111 - mean_squared_error: 2.2111 - mean_absolute_error: 1.1066 - val_loss: 1.4688 - val_mean_squared_error: 1.4688 - val_mean_absolute_error: 0.9819\n",
      "Epoch 10/300\n",
      "677/677 [==============================] - 1s 834us/step - loss: 1.9248 - mean_squared_error: 1.9248 - mean_absolute_error: 1.0215 - val_loss: 0.8887 - val_mean_squared_error: 0.8887 - val_mean_absolute_error: 0.7655\n",
      "Epoch 11/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 1.4927 - mean_squared_error: 1.4927 - mean_absolute_error: 0.9024 - val_loss: 0.9101 - val_mean_squared_error: 0.9101 - val_mean_absolute_error: 0.7649\n",
      "Epoch 12/300\n",
      "677/677 [==============================] - 1s 837us/step - loss: 1.3791 - mean_squared_error: 1.3791 - mean_absolute_error: 0.8733 - val_loss: 1.0726 - val_mean_squared_error: 1.0726 - val_mean_absolute_error: 0.7894\n",
      "Epoch 13/300\n",
      "677/677 [==============================] - 1s 840us/step - loss: 1.3025 - mean_squared_error: 1.3025 - mean_absolute_error: 0.8548 - val_loss: 0.8863 - val_mean_squared_error: 0.8863 - val_mean_absolute_error: 0.7264\n",
      "Epoch 14/300\n",
      "677/677 [==============================] - 1s 843us/step - loss: 1.1567 - mean_squared_error: 1.1567 - mean_absolute_error: 0.8073 - val_loss: 1.1704 - val_mean_squared_error: 1.1704 - val_mean_absolute_error: 0.8355\n",
      "Epoch 15/300\n",
      "677/677 [==============================] - 1s 842us/step - loss: 1.1845 - mean_squared_error: 1.1845 - mean_absolute_error: 0.7898 - val_loss: 1.1657 - val_mean_squared_error: 1.1657 - val_mean_absolute_error: 0.8555\n",
      "10/10 - 0s - loss: 0.8887 - mean_squared_error: 0.8887 - mean_absolute_error: 0.7655 - 58ms/epoch - 6ms/step\n",
      "Test MSE: 0.8886518478393555    Test MAE: 0.7654646039009094  \n"
     ]
    }
   ],
   "source": [
    "METRICS = []\n",
    "\n",
    "MODEL_LABELS = {\"linearSGD\": \"MLR\",\n",
    "                \"svr\": \"SVR\",\n",
    "                \"mlp\": \"MLP\"}\n",
    "\n",
    "for modelID in modelsID:\n",
    "    X =copy.deepcopy(data.X)\n",
    "    y =copy.deepcopy(data.y)\n",
    "\n",
    "    skf = KFold(n_splits=N_splits,shuffle=True)\n",
    "    for k, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            data.X_train,data.y_train = X[train_index],y[train_index]\n",
    "            data.X_test, data.y_test  = X[test_index],y[test_index]\n",
    "            model = modelGenerator(modelID=modelID, data=data,params={})\n",
    "            model.train()\n",
    "            METRICS.append([MODEL_LABELS[modelID],k,\"MAE\",model.test_MAE])\n",
    "            METRICS.append([MODEL_LABELS[modelID],k,\"MSE\",model.test_MSE])\n",
    "            del model\n",
    "            K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{MAE} & \\multicolumn{2}{l}{MSE} \\\\\n",
      "{} &  mean &   std &  mean &   std \\\\\n",
      "Model &       &       &       &       \\\\\n",
      "\\midrule\n",
      "MLR   & 0.806 & 0.051 & 1.062 & 0.259 \\\\\n",
      "SVR   & 1.815 & 0.687 & 4.691 & 3.750 \\\\\n",
      "MLP   & 0.626 & 0.065 & 0.720 & 0.345 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_845633/4070562265.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(table_metrics.to_latex(float_format=\"%1.3f\"))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_metrics = pd.DataFrame(METRICS,columns = ['Model','k','METRICS','VALUES'])\n",
    "table_metrics = df_metrics.pivot_table(index='Model',columns='METRICS',values=\"VALUES\",aggfunc=[np.mean, np.std])\n",
    "table_metrics = table_metrics.swaplevel(axis=1)\n",
    "table_metrics.sort_index(axis=1,inplace=True)\n",
    "table_metrics.columns.names = (None,None)\n",
    "table_metrics = table_metrics.reindex([MODEL_LABELS[model] for model in modelsID])\n",
    "print(table_metrics.to_latex(float_format=\"%1.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiwind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
